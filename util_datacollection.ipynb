{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from bs4 import BeautifulSoup\n",
    "import sys, os\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import codecs \n",
    "import numpy as np \n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "import numpy as np \n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "from dateutil import parser\n",
    "import pandas as pd \n",
    "from time import sleep\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse as urlparse\n",
    "from urllib.parse import parse_qs\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import os \n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pysal as ps \n",
    "import utm \n",
    "import geopandas \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grab_source(letter,path):\n",
    "\n",
    "  \n",
    "    \"\"\"\n",
    "    Queries the Real Property Parcer of erie county(Specifically only SBL values), which can be found on this link:\n",
    "                            http://www2.erie.gov/ecrpts/index.php?q=real-property-parcel-search\n",
    "    This function will return a beautiful soup object of the source code of a SBL's tax History.\n",
    "    :param sbl: SBL value that we are searching for\n",
    "    :param mode: it can be tax information history for: \"ecgov\", or owner history for anything else\n",
    "    :return: a Beautiful soup object of the tax extry history of that SBL\n",
    "    \"\"\"\n",
    "    path= os.path.join(path, 'SCRAPED_DATA_property_information')\n",
    "    path2 = os.path.join(path, 'SCRAPED_DATA_owner_history')\n",
    "    os.mkdir(path)\n",
    "    os.mkdir(path2)\n",
    "    body = {'txtsbl': letter, \n",
    "            'Juris': '1402',# WE CAN CHANGE THIS TO SBL BUT THIS IS OWNER NAME\n",
    "            'showHistory': 'y'}\n",
    "    url2 = 'https://paytax.erie.gov/webprop/'  # url we needed adding to since this is the root link\n",
    "    url = 'https://paytax.erie.gov/webprop/property_info_results.asp'  # search website\n",
    "    s_request = requests.Session()\n",
    "    link = s_request.post(url, data=body)\n",
    "    source_soup = BeautifulSoup(link.content, 'html.parser')\n",
    "    while(len(source_soup.find_all('a', href=True)) > 1):\n",
    "        for owner in source_soup.find_all('a', href=True):\n",
    "            if str(owner['href']).startswith(\"property_info_details\"): \n",
    "                con2 = requests.post(url2+owner['href'])\n",
    "                details_soup = BeautifulSoup(con2.content, 'lxml')\n",
    "                html_file = urlparse.urlparse(owner['href']).query.split(\"&\")[0].replace('.','#').replace('/','+') + \".html\"\n",
    "                with open(path2 +  html_file, \"w\", encoding='utf-8') as file:\n",
    "                            file.write(str(details_soup)) \n",
    "                for a in details_soup.find_all('a', href=True):\n",
    "                    if str(a['href']).startswith('property_info_history.asp'):\n",
    "                        s = BeautifulSoup(requests.post(url2 + a['href']).content,'lxml')\n",
    "                        with open(path +  html_file, \"w\", encoding='utf-8') as file:\n",
    "                            file.write(str(s)) \n",
    "                            return html_file\n",
    "            elif str(owner['href']).startswith(\"property_info_results_next\"):\n",
    "                con3 = s_request.post(url2+owner['href'],headers= headers)\n",
    "                source_soup = BeautifulSoup(con3.content, 'lxml')\n",
    "        if len(source_soup.find_all(lambda tag: \"Last Record Found\" in tag.string if tag.string else False)) > 0: # that means this page is the last record \n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_considerations_page(owner_history_df,path):\n",
    "    \"\"\"\n",
    "        Queries the Real Property Parcer of erie county(Specifically only SBL values), which can be found on this link:\n",
    "                                http://www2.erie.gov/ecrpts/index.php?q=real-property-parcel-search\n",
    "        This function will return a beautiful soup object of the source code of a SBL's tax History.\n",
    "        :param sbl: SBL value that we are searching for\n",
    "        :param mode: it can be tax information history for: \"ecgov\", or owner history for anything else\n",
    "        :return: a Beautiful soup object of the tax extry history of that SBL\n",
    "    \"\"\"\n",
    "\n",
    "    path= os.path.join(path, 'considerations_htmls')\n",
    "    os.mkdir(path)\n",
    "    counter = 0\n",
    "    for sbl, deed_page in owner_history_df[['SBL','Book-Page']].to_records(index=False):\n",
    "        try:\n",
    "            file_name = sbl + \"+\" + deed_page \n",
    "            print(\"FILE:\" + file_name)\n",
    "            file_name = file_name.replace('.','#').replace('/','$')\n",
    "            body = {'search_entry': deed_page,  # WE CAN CHANGE THIS TO SBL BUT THIS IS OWNER NAME\n",
    "                    'search_by': 'Dynamic Book/Page'}\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "            url2 ='http://ecclerk.erie.gov/or_wb1/'  # url we needed adding to since this is the root link\n",
    "\n",
    "            url = 'http://ecclerk.erie.gov/or_wb1/new_sch.asp'  # search website\n",
    "            link = requests.post(url, data=body,headers = headers )\n",
    "            source_soup = BeautifulSoup(link.content, 'html.parser')\n",
    "            owner = source_soup.find_all('a', {'class': 'list_2'})\n",
    "            counting = 1 \n",
    "            for own in owner:\n",
    "                con2 = requests.post(url2+ ''.join(own['href'].split()))\n",
    "                details_soup = BeautifulSoup(con2.content, 'lxml')    \n",
    "                with open(path+file_name+\"&\" + str(counting) + \".html\",\"w\") as of:\n",
    "                    of.write(str(details_soup.html)) \n",
    "                counting += 1\n",
    "            counter += 1 \n",
    "        except Exception as e:\n",
    "            print('failure on----------------------')\n",
    "            print(sbl)\n",
    "            print(deed_page)\n",
    "            print(e)\n",
    "            #lst_failed.append([deed_page,sbl])\n",
    "        print(counter/len(df2) * 100)\n",
    "        clear_output(wait = True)\n",
    "            #print(pd.read_html(str(details_soup))[4][1][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_csv_converter(files,csv_name):\n",
    "    \n",
    "    counter = 0\n",
    "    lst_failed =[] \n",
    "    for file_name in files:\n",
    "        x= file_name.replace('#','.').replace('+','/')[:-5]\n",
    "        try:\n",
    "            with open(path +  file_name, \"r\", encoding='utf-8') as file:\n",
    "                        data= file.read()\n",
    "\n",
    "            df= pd.read_html(str(data))[0]\n",
    "            df['SBL'] = file_name.replace('#','.').replace('+','/')[:-5]\n",
    "            df.to_csv('../../../data/gentrification/LATEST/' + csv_name , mode='a', header=False,index = False)\n",
    "            counter += 1 \n",
    "        except:\n",
    "            lst_failed.append(file_name)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def owner_history_error_reformat(owner_history_df,open_data_df, inplace = False):\n",
    "\n",
    "    '''\n",
    "    use open data informtation to replace errors \n",
    "    and noise within the original data \n",
    "    '''\n",
    "    if not inplace:\n",
    "        owner_history_df = owner_history_df.copy()\n",
    "    owner_history_deeds = owner_history_df['Book-Page/Date identification'].str.split('*').str[0].str.replace(' ','').str.replace('-','/')\n",
    "    owner_history_df['Book-Page'] = owner_history_deeds\n",
    "    index_of_nan = owner_history_deeds[owner_history_deeds.apply(lambda x: True if x != x else False )].index\n",
    "    index_of_errors = owner_history_deeds.loc[list(index_of_nan)].index\n",
    "\n",
    "    nan_removed_owner_history = owner_history_deeds.loc[np.delete(owner_history_deeds.index,index_of_errors)]\n",
    "    parsing_errors = nan_removed_owner_history[nan_removed_owner_history.apply(lambda x: '/' not in x)].index\n",
    "    all_errors = np.append(index_of_nan,parsing_errors)\n",
    "    owner_history_deeds.loc[parsing_errors] = owner_history_df.loc[parsing_errors]['Book-Page/Date identification'].str.split().apply(lambda i: i[0]).str.replace('-','/').str.replace('*','')\n",
    "\n",
    "    open_data_df['Book-Page/Date identification'] = open_data_df[['DEED BOOK', 'DEED PAGE']].apply(lambda x: str(x[0]) + \"/\" + str(x[1]), axis =1 )\n",
    "    new_deeds_from_ODB = open_data_df[['Book-Page/Date identification','PRINT KEY']].set_index('PRINT KEY').to_dict()['Book-Page/Date identification']\n",
    "    owner_history_df.loc[all_errors,'Book-Page'] = owner_history_df.loc[all_errors]['SBL'].map(new_deeds_from_ODB)\n",
    "    return owner_history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_considerations_owner_history(file_path,csv_name):\n",
    "   \n",
    "    appended_data_frame = []\n",
    "    counter = 0\n",
    "    lst_failed= []\n",
    "    dct = defaultdict(list)\n",
    "    files = os.listdir(file_path)\n",
    "    for file_name in files: \n",
    "        with open(file_path + file_name, \"r\", encoding='utf-8') as file:\n",
    "                data = file.read()\n",
    "        name = fl[:-5].replace('#','.').replace('$','/')\n",
    "        sbl = name.split(\"+\")[0]\n",
    "        deed_page = name.split(\"+\")[1].split(\"&\")[0]\n",
    "        doc_types = []\n",
    "        try:\n",
    "           \n",
    "            consideration_page_df= pd.read_html(str(data))\n",
    "        except Exception as e:\n",
    "            lst_failed.append([fl,e])\n",
    "            lst.append([sbl,np.nan,np.nan,deed_page,np.nan,np.nan])\n",
    "            counter += 1 \n",
    "            continue \n",
    "\n",
    "        doc_type = consideration_page_df[4][1][0]\n",
    "        consideration = consideration_page_df[4][1][6]\n",
    "        date = consideration_page_df[4][1][2]\n",
    "        url_book_page = consideration_page_df[4][1][4]\n",
    "        dct_name = sbl + \"+\" + deed_page\n",
    "        print(counter/len(files)*100)\n",
    "        if doc_type not in dct[dct_name]:\n",
    "            appended_data_frame.append([sbl,consideration,doc_type,deed_page,url_book_page,date])\n",
    "            dct[dct_name].append(doc_type)\n",
    "        counter += 1 \n",
    "        clear_output(wait = True) \n",
    "        df = pd.DataFrame(appended_data_frame, columns = ['SBLS','considerations','doc type','deed page(search parcel)','deed page(public records)','date(public records)'])\n",
    "        df.to_csv(os.path.join(file_path,csv_name),index = False)\n",
    "        return lst_failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_initialization(df_data,column_name_of_locations):\n",
    "    '''\n",
    "    Initializes neighborhood weights \n",
    "    '''\n",
    "\n",
    "    df_data = data_frame_construction_for_rf(df_data)\n",
    " \n",
    "    #-------------------------------------------------\n",
    "    sbls = df_data.drop_duplicates('sbl')[['sbl',column_name_of_locations]]\n",
    "    locations_sbls = sbls[column_name_of_locations].apply(lambda x: [ float(n.replace('(','').replace(')',''))  for n in x.split(',')])\n",
    "    sbls['locs'] = locations_sbls.apply(lambda pt: utm.from_latlon(pt[0],pt[1])[:2])\n",
    "    sbls['utm'] = sbls['locs'].apply(lambda pt: [pt[0],pt[1]])\n",
    "    unique_sbls = df_data['sbl'].unique()\n",
    "    res_loc = geopandas.GeoDataFrame(sbls, geometry=geopandas.points_from_xy(sbls['locs'].apply(lambda x: x[0]), sbls['locs'].apply(lambda y: y[1])))\n",
    "    res_loc = res_loc.reset_index(drop = True)\n",
    "    tester = geopandas.GeoDataFrame(res_loc).reset_index(drop = True)\n",
    "    w300=ps.lib.weights.DistanceBand.from_dataframe(tester,threshold =300, ids = 'sbl', binary = False, p = 2)\n",
    "    w500=ps.lib.weights.DistanceBand.from_dataframe(tester,threshold =500, ids = 'sbl', binary = False, p = 2)\n",
    "    w80 =ps.lib.weights.DistanceBand.from_dataframe(tester,threshold =100, ids = 'sbl', binary = False, p = 2)\n",
    "    return w300,w500,w80, df_data, unique_sbls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier_data_pre_processing(data_frame,open_dat):\n",
    "\n",
    "    # permits data acess \n",
    "    \n",
    "    permits_data =  pd.read_csv('https://data.buffalony.gov/api/views/9p2d-f3yt/rows.csv?accessType=DOWNLOAD', low_memory= False)\n",
    "    \n",
    "    permits_data['ISSUED'] = pd.to_datetime(permits_data['ISSUED'])\n",
    "    permits = open_dat[['SBL','PRINT KEY',]].merge(permits_data, on = 'SBL', how = 'right')\n",
    "    permits = permits.rename(columns = {'PRINT KEY':'sbl'}).drop('SBL',axis =1 )\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # -------  Weights and data initialization ------------------------\n",
    "    data_frame = data_frame.copy()\n",
    "    to_dataframe = defaultdict(list)\n",
    "    counter = 0\n",
    "    list_of_neighborhoods = data_frame['Neighborhood'].unique()[:-1]\n",
    "    w500, w300, w80, data_frame, unique_sbls = weights_initialization(data_frame, 'Location')\n",
    "    dates_six = pd.date_range(start=\"1993-12-01\",end=\"2021-12-01\", freq='A-DEC')[1:]\n",
    "    last_date = dates_six[0]\n",
    "    \n",
    "    # -------- loop feature collection --------------------------------\n",
    "    \n",
    "    for dates in dates_six[1:]: # we start from the second to the first date\n",
    "        timedelta_days = (dates - parser.parse('1854-10-01')).days\n",
    "        three_months = last_date + timedelta(90)\n",
    "        last_year = last_date - timedelta(365)\n",
    "        last_2year = last_date - timedelta(730)\n",
    "        last_3year = last_date - timedelta(1095)\n",
    "        last_45_year = last_date - timedelta(1825)\n",
    "        #------\n",
    "        length = data_frame[data_frame['Actual Date'] > last_date][data_frame['Actual Date'] <= dates]\n",
    "        sbls_bought_this_year =  np.array(length['sbl']) # drop duplicates dates here just to be safe \n",
    "        #----\n",
    "        length_3month = data_frame[data_frame['Actual Date'] > last_date][data_frame['Actual Date'] <= three_months]\n",
    "        sbls_bought_3month =  np.array(length_3month['sbl'])\n",
    "        #-----\n",
    "        length_last_year = data_frame[data_frame['Actual Date'] >= last_year][data_frame['Actual Date'] <= last_date]\n",
    "        sbls_bought_last_year =  set(np.array(length_last_year['sbl']))\n",
    "        perm_last_year = permits[permits['ISSUED'] >= last_year][permits['ISSUED'] <= last_date]\n",
    "        #----\n",
    "        length_last_2year = data_frame[data_frame['Actual Date'] >= last_2year][data_frame['Actual Date'] <= last_year]\n",
    "        sbls_bought_last_2year =  np.array(length_last_2year['sbl'])\n",
    "        perm_last_2year = permits[permits['ISSUED'] >= last_2year][permits['ISSUED'] <= last_year]\n",
    "        # -- \n",
    "        length_last_3year = data_frame[data_frame['Actual Date'] >= last_3year][data_frame['Actual Date'] <= last_2year]\n",
    "        sbls_bought_last_3year =  np.array(length_last_3year['sbl'])\n",
    "        perm_last_3year = permits[permits['ISSUED'] >= last_3year][permits['ISSUED'] <= last_2year]\n",
    "        # -- \n",
    "        length_last_45year = data_frame[data_frame['Actual Date'] >= last_45_year][data_frame['Actual Date'] <= last_3year]\n",
    "        sbls_bought_last_45year =  np.array(length_last_45year['sbl'])\n",
    "        perm_last_45year = permits[permits['ISSUED'] >= last_45_year][permits['ISSUED'] <= last_3year]\n",
    "        new_counter = 0\n",
    "        # must double check if this data path file is in the server \n",
    "        df = pd.read_csv('/data/gentrification/TAX_DATA/Tax_Data/tax_data-' + str(last_date.year) + '.csv')\n",
    "        try: \n",
    "            df_last3year = pd.read_csv('/data/gentrification/TAX_DATA/Tax_Data/tax_data-' + str(last_3year_bill_change) + '.csv')\n",
    "        except:\n",
    "            df_last3year = None \n",
    "        new_counter = 0\n",
    "        counter +=  1 \n",
    "        for sbl in unique_sbls:\n",
    "            to_dataframe['SBL'].append(sbl)# SBL COLUMN\n",
    "            to_dataframe['Timedelta'].append(timedelta_days)\n",
    "            to_dataframe['Year'].append(dates.year)\n",
    "            new_counter += 1 \n",
    "            print( \"OVERALL:\" + str(counter / len(dates_six[1:]) * 100) + \" |UNIQUE SBLS SECTION:\"+ str(new_counter / len(unique_sbls) * 100))\n",
    "            bought_this_year = True if sbl in sbls_bought_this_year else False\n",
    "            to_dataframe['If Bought This Year'].append(bought_this_year) # IF HOUSE BOUGHT THIS YEAR COLUMN\n",
    "            bought_first_three = True if sbl in sbls_bought_3month else False\n",
    "            to_dataframe['Bought The First Three Months This Year'].append(bought_first_three) # IF HOUSE IS BOUGHT THE FIRST MONTHS THIS YEAR, THIS COLUMN WILL BE REMOVED\n",
    "            bought_last_year = True if sbl in sbls_bought_last_year else False\n",
    "            to_dataframe['If House is Bought Last Year'].append(bought_last_year) # IF HOUSE IS BOUGHT LAST YEAR\n",
    "            bought_last_2year = True if sbl in sbls_bought_last_2year else False\n",
    "            to_dataframe['If House is Bought Last 2 Years Ago'].append(bought_last_2year) # IF HOUSE IS BOUGHT LAST 2 Years Ago\n",
    "\n",
    "            #--------------------------------------------------------------------------------\n",
    "            neighbors_300 = w300.neighbors[sbl]\n",
    "            neighbors_500 = w500.neighbors[sbl]    # LIST OF NEIGHBORS \n",
    "            neighbors_80 = w80.neighbors[sbl]\n",
    "            n500 = data_frame[data_frame['sbl'].isin(neighbors_500)][data_frame['Actual Date'] <= last_date]\n",
    "            n300 = data_frame[data_frame['sbl'].isin(neighbors_300)][data_frame['Actual Date'] <= last_date]\n",
    "            n80 = data_frame[data_frame['sbl'].isin(neighbors_80)][data_frame['Actual Date'] <= last_date]\n",
    "\n",
    "\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "            # Column for number of houses (80m) bought last year ago\n",
    "            num_neighbors_bought_80_last_year = pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought Last Year'].append(num_neighbors_bought_80_last_year) \n",
    "            # Column for number of houses (80m) bought last 2 years ago\n",
    "            num80_2yearsago = pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 2 Years Ago'].append(num80_2yearsago)\n",
    "            # Column for number of houses (80m) bought last 3 years ago \n",
    "            num80_3yearsago = pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 3 Years Ago'].append(num80_3yearsago)\n",
    "            # Column for number of houses (80m) bought last 4 years ago \n",
    "            num80_45yearsago =pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 4 Years Ago'].append(num80_45yearsago)\n",
    "\n",
    "\n",
    "            #------------------------------------------------------------------------- # do duplicates here \n",
    "            # Column for number of houses bought (300m) bought last year ago \n",
    "            num_neighbors_bought_300_last_year = pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_300]).sum()  \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought Last Year'].append(num_neighbors_bought_300_last_year)\n",
    "            # Column for number of houses bought (300m) * Not Going to add this column\n",
    "            #num_neighbors_bought_300_3mnth =   pd.Series([ 1 for i in sbls_bought_3month if i in neighbors_300]).sum()     \n",
    "            # Column for number of houses bought (300m) bought 2 years ago   \n",
    "            num300_2yearsago =  pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_300]).sum() \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 2 years ago'].append(num300_2yearsago)\n",
    "            # Column for number of houses bought (300m) bought 3 years ago\n",
    "            num300_3yearsago =  pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_300]).sum()   \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 3 years ago'].append(num300_3yearsago)\n",
    "            # Column for number of houses bought (300m) bought 3 years ago \n",
    "            num300_45yearsago = pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_300]).sum()  \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 4-5 years ago'].append(num300_45yearsago)\n",
    "           # ------------------------------------------------------------------------------------------\n",
    "            #num_neighbors_bought_500_6mnth =  pd.Series([ 1 for i in sbls_bought_this_year if i in neighbors_500]).sum()  \n",
    "            #num_neighbors_bought_500_3mnth =  pd.Series([ 1 for i in sbls_bought_3month if i in neighbors_500]).sum()   \n",
    "            # Column for number of houses bought (500m) last year ago \n",
    "            num500_1yearsago =  pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_500]).sum() \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought last year ago'].append(num500_1yearsago)\n",
    "            # Column for number of houses bought (500m) last 2 years ago \n",
    "            num500_2yearsago =  pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_500]).sum() \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 2 years ago'].append(num500_2yearsago)\n",
    "            # Column for number of houses bought (500m) last 3 years ago \n",
    "            num500_3yearsago =  pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_500]).sum()  \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 3 years ago'].append(num500_3yearsago)\n",
    "            # Column for number of houses bought (500m) last 4-5 years ago \n",
    "            num500_45yearsago = pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_500]).sum()   \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 4-5 years ago'].append(num500_45yearsago)\n",
    "            #print(num_neighbors_bought_500_6mnth)   \n",
    "\n",
    "            to_dataframe['Year | Month'].append(str(dates.year) + \"|\" + str(dates.month))\n",
    "            #----------------PERMITS-----------------------------------------------------------------\n",
    "\n",
    "            perm_500_lst_year =  perm_last_year[perm_last_year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_2year500 = perm_last_2year[perm_last_2year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_3year500 = perm_last_3year[perm_last_3year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_45year500 = perm_last_45year[perm_last_45year['sbl'].isin(neighbors_500)]\n",
    "\n",
    "\n",
    "\n",
    "            #\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "            perm_80_lst_year =  perm_last_year[perm_last_year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_2year80 = perm_last_2year[perm_last_2year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_3year80 = perm_last_3year[perm_last_3year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_45year80 = perm_last_45year[perm_last_45year['sbl'].isin(neighbors_80)]\n",
    "\n",
    "            #-----------------------------------------------------------------------------------------\n",
    "\n",
    "            clear_output(wait=False)\n",
    "            ave_time_deltas = 0\n",
    "\n",
    "            ave_price_sold_last_year_500 = n500[n500['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_300 = n300[n300['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_80 = n80[n80['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_500_change = n500[n500['Actual Date'] >= last_3year][n500['Actual Date'] <= last_2year]['Price'].mean()\n",
    "            ave_price_sold_last_year_500_change = (ave_price_sold_last_year_500 - ave_price_sold_last_year_500_change) / ave_price_sold_last_year_500_change\n",
    "            ave_bill_neighbors500 = df[df['SBL'].isin(neighbors_500)]['Principal'].astype(float).mean()\n",
    "            sbl_last_year_500 = n500[n500['Actual Date'] >= last_year][['sbl','Price']].rename(columns = {'sbl':'SBL'}) # 500m radius bought last year \n",
    "            ratio = df[df['SBL'].isin(sbl_last_year_500['SBL'].unique())][['SBL','Principal']].set_index('SBL').to_dict()['Principal']\n",
    "            sbl_last_year_500['princ'] = sbl_last_year_500['SBL'].map(ratio)\n",
    "            num_foreclosures500 = len(n500[n500['Actual Date'] >= last_3year][n500['doc type'] == 'D1D']) \n",
    "            num_foreclosures300 = len(n300[n300['Actual Date'] >= last_3year][n300['doc type'] == 'D1D']) \n",
    "            num_foreclosures80 = len(n80[n80['Actual Date'] >= last_3year][n80['doc type'] == 'D1D']) \n",
    "            perms_3 = len(permits[permits['ISSUED'] >= last_3year][permits['ISSUED'] <= last_date][permits['sbl'].isin(neighbors_500)])\n",
    "            try:\n",
    "                rat = sbl_last_year_500[sbl_last_year_500['Price'] != 0][sbl_last_year_500['princ'] != 0] \n",
    "                mean_ratio = rat.apply(lambda x: x['Price'] / x['princ'], axis =1 ).apply(lambda i: i if isinstance(i,float) else np.nan).dropna().mean()\n",
    "\n",
    "                if not isinstance(mean_ratio,float):\n",
    "                    mean_ratio = 0\n",
    "            except Exception as e:\n",
    "                mean_ratio = 0 \n",
    "                print(e)\n",
    "\n",
    "            try:\n",
    "                my_bill = df[df['SBL'] == sbl]['Principal'].astype(float)\n",
    "                my_bill = my_bill.iloc[0] if len(my_bill) > 0 else 0  \n",
    "                std_bill = my_bill - ave_bill_neighbors500\n",
    "            except:\n",
    "                std_bill =  0\n",
    "            try:\n",
    "                my_bill_last3 = df_last3year[df_last3year['SBL'] == sbl]['Principal'].astype(float) if df_last3year != None else None \n",
    "                my_bill_last3 =  my_bill_last3.iloc[0] if my_bill_last3 != None and len(my_bill_last3) > 0 else 0  \n",
    "                bill_change= (my_bill - my_bill_last3) / my_bill_last3 if my_bill_last3 != -1 and my_bill != -1 else 0 \n",
    "            except: \n",
    "                bill_change = 0\n",
    "\n",
    "            ave_interest_near_me = df[df['SBL'].isin(neighbors_500)]['Pd Intr'].astype(float).mean()\n",
    "            try:\n",
    "                ave_time_deltas =  n500[n500['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas =  ave_time_deltas[ave_time_deltas  >= 0].mean() if len(ave_time_deltas) > 0else 0\n",
    "                ave_time_deltas300 =  n300[n300['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas300 =  ave_time_deltas300[ave_time_deltas300  >= 0].mean() if len(ave_time_deltas300) > 0 else 0 \n",
    "                ave_time_deltas80 =  n80[n80['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas80 =  ave_time_deltas80[ave_time_deltas80  >= 0].mean() if len(ave_time_deltas80) > 0 else 0\n",
    "\n",
    "                ave_p500 = permits[permits['sbl'].isin(neighbors_500)][permits['ISSUED'] <= last_date]['ISSUED'].apply(lambda p: (last_date - p).days).mean()\n",
    "                ave_p80 = permits[permits['sbl'].isin(neighbors_80)][permits['ISSUED'] <= last_date]['ISSUED'].apply(lambda p: (last_date - p).days).mean()\n",
    "            except Exception as e:\n",
    "                ave_time_deltas = 0\n",
    "                ave_time_deltas300 = 0\n",
    "                ave_time_deltas80 = 0\n",
    "                print(\"OH NO\")\n",
    "                print(e)\n",
    "                pass \n",
    "            try:\n",
    "                house_length_homeownership = (last_date - data_frame[data_frame['sbl'] == sbl][data_frame['Actual Date'] <= last_date].iloc[-1]['Actual Date']).days\n",
    "            except:\n",
    "                house_length_homeownership = 0\n",
    "            to_dataframe['Average length of homeownership (500m radius)'].append(ave_time_deltas)\n",
    "            to_dataframe['length of homeownership (this house)'].append(house_length_homeownership)\n",
    "            to_dataframe['Average bill of neighbors (500m radius) from last year'].append(ave_bill_neighbors500)\n",
    "            to_dataframe['This house\\'s bill last year'].append(my_bill)\n",
    "            to_dataframe['Average interest of neighbors (500m radius) last year'].append(ave_interest_near_me)\n",
    "            to_dataframe['Difference between SBL bill and neighbors (500m) last year'].append(std_bill)\n",
    "            to_dataframe['Average length of homeownership (300m radius)'].append(ave_time_deltas300)\n",
    "            to_dataframe['This sbl\\'s bill percent change from last 3 years ago to last year'].append(bill_change)\n",
    "            to_dataframe['Average length of homeownership (80m radius)'].append(ave_time_deltas80)\n",
    "            to_dataframe['Average price sold of neighbors (500m radius) last year'].append(ave_price_sold_last_year_500)\n",
    "            to_dataframe['Average price sold of neighbors (300m radius) last year'].append(ave_price_sold_last_year_300)\n",
    "            to_dataframe['Average price sold of neighbors (80m radius) last year'].append(ave_price_sold_last_year_80)\n",
    "            to_dataframe['Average percent change of house price transaction from last 3 years ago, to last year'].append(ave_price_sold_last_year_500_change)\n",
    "            to_dataframe['Mean ratio of bill to house price transaction from last year (500m raidus)'].append(mean_ratio)\n",
    "            to_dataframe['Number of permits last year in a (5oom) radius'].append(len(perm_500_lst_year))\n",
    "            to_dataframe['Number of permits last 2 years ago in a (500m) radius'].append(len(perm_last_2year500))\n",
    "            to_dataframe['Number of permits last 3 years ago in a (500m) radius'].append(len(perm_last_3year500))\n",
    "            to_dataframe['Number of permits last 4-5 years ago in a (500m) radius'].append(len(perm_last_45year500))\n",
    "            to_dataframe['Number of permits last year in a (80m) radius'].append(len(perm_80_lst_year))\n",
    "            to_dataframe['Number of permits last 2 years ago in a (80m) radius'].append(len(perm_last_2year80))\n",
    "            to_dataframe['Number of permits last 3 years ago in a (80m) radius'].append(len(perm_last_3year80))\n",
    "            to_dataframe['Number of permits last 4-5 years ago in a (80m) radius'].append(len(perm_last_45year80))\n",
    "            to_dataframe['Mean Value of work (Permits) in a (500m) radius last year'].append(perm_500_lst_year['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (500m) radius last 2 years ago'].append(perm_last_2year500['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (80m) radius last year'].append(perm_80_lst_year['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (80m) radius last 2 years ago'].append(perm_last_2year80['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Average length of time since the last permits issued in a (500m) radius'].append(ave_p500)\n",
    "            to_dataframe['Average length of time since the last permits issued in a (80m) radius'].append(ave_p80)\n",
    "            to_dataframe['Number of foreclosures in a (500m) radius, from last 3 years ago till last year'].append(num_foreclosures500)\n",
    "            to_dataframe['Number of foreclosures in a (300m) radius, from last 3 years ago till last year'].append(num_foreclosures300)\n",
    "            to_dataframe['Number of foreclosures in a (80m) radius, from last 3 years ago till last year'].append(num_foreclosures80)\n",
    "            to_dataframe['Number of Permits from last 3 years ago, to last year, in a (500m) radius'].append(perms_3)\n",
    "            try:\n",
    "                neighbor_name  = neigh[sbl]\n",
    "            except:\n",
    "                neighbor_name = 'UNKNOWN' \n",
    "\n",
    "            # one hot encode neighborhoods \n",
    "            for neighborhood in list_of_neighborhoods:\n",
    "                if neighborhood == neighborhood and neighborhood != neighbor_name:\n",
    "                    to_dataframe[neighborhood].append(0)\n",
    "                else: \n",
    "                    to_dataframe[neighbor_name].append(1) \n",
    "            # this way its just easier to name columns\n",
    "        last_date = dates\n",
    "    return pd.DataFrame(to_dataframe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_locations(data, open_data_df):\n",
    "    neigh_map = open_data_df[['PRINT KEY','NEIGHBORHOOD']].set_index('PRINT KEY').to_dict()['NEIGHBORHOOD']\n",
    "    location_map = open_data_df[['PRINT KEY','LOCATION']].set_index('PRINT KEY').to_dict()['LOCATION']\n",
    "    data['Neighborhood'] = data['sbl'].map(neigh_map)\n",
    "    data['Location'] = data['sbl'].map(location_map)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_apartments(data,path):\n",
    "    path_property_information = os.path.join(path, 'SCRAPED_DATA_property_information' ) # will chnage to 'SCRAPED_DATA_property_information'\n",
    "    path_owner_history = os.path.join(path, 'SCRAPED_DATA_owner_history') \n",
    "    lists = os.listdir(path_property_information)\n",
    "    list_of_failed_files = []\n",
    "    counter = 0\n",
    "    lists_of_residential_sbls = []\n",
    "    list_of_anomolies = []\n",
    "    for i in lists:\n",
    "        try:\n",
    "            print(counter / len(lists) * 100)\n",
    "            property_information_sbl_path  = os.path.join(path_property_information,i)\n",
    "            owner_history_sbl_path = os.path.join(path_owner_history,i)\n",
    "            f_front_htmls =codecs.open(property_information_sbl_path, 'r')\n",
    "            f_owner_history_htmls =codecs.open(owner_history_sbl_path, 'r')\n",
    "            soup_front_htmls = BeautifulSoup(str(f_front_htmls.read()),'html.parser')\n",
    "            soup_owner_history_htmls = BeautifulSoup(str(f_owner_history_htmls.read()),'html.parser')\n",
    "\n",
    "            df_front_htmls = pd.read_html(property_information_sbl_path)[0]\n",
    "            df_owner_history_htmls = pd.read_html(owner_history_sbl_path)[0]\n",
    "            num_of_res =  df_front_htmls[1].apply(lambda x: 'RES' in x.split() if x == x else False).sum() \n",
    "            if num_of_res > 0 and num_of_res < 2:\n",
    "                lists_of_residential_sbls.append(i.split('=')[1][:-5].replace('#','.').replace('+','/'))\n",
    "            elif num_of_res == 0: # does not contain any residential\n",
    "                continue\n",
    "            else:\n",
    "             \n",
    "                list_of_anomolies.append(df_front_htmls[1])\n",
    "            \n",
    "            counter += 1 \n",
    "            clear_output()\n",
    "        except Exception as p:\n",
    "            list_of_failed_files.append(i)\n",
    "    \n",
    "    lists_of_residential_sbls = np.array(lists_of_residential_sbls)\n",
    "    return data[data['sbl'].isin(lists_of_residential_sbls)], list_of_failed_files, list_of_anomolies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame_construction_for_rf(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe['Price'] = dataframe['consideration'].apply(lambda i: float(i.replace('$','').replace(',','')) if i == i else np.nan )\n",
    "    dataframe =  dataframe[~dataframe['Actual Date'].isna()]\n",
    "    dataframe = dataframe[dataframe['Price']  > 1]\n",
    "    dataframe_more_than_one_doc_type = dataframe[dataframe['more than one doc type']]\n",
    "    index_of_single_doc =  dataframe_more_than_one_doc_type.drop_duplicates(['sbl','Actual Date']).index\n",
    "    idx_to_remove = dataframe_more_than_one_doc_type[~dataframe_more_than_one_doc_type.index.isin(index_of_single_doc)].index \n",
    "    dataframe = dataframe.drop(idx_to_remove)\n",
    "    dataframe = dataframe[~dataframe['Location'].isnull()]\n",
    "    dataframe= dataframe.sort_values(by = 'Actual Date')\n",
    "    dataframe['Actual Date'] = pd.to_datetime(dataframe['Actual Date'])\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_geoencode_missing_location(dataframe,path):\n",
    "    dataframe = dataframe.copy()\n",
    "    oarsystem_data_path = os.path.join(path,'buffalo_oarsystem_CSVs/combined_tax_data.csv')\n",
    "    oarsystem_df = pd.read_csv(os.path.join(oarsystem_data_path)).rename(columns = {'SBL':'sbl'})\n",
    "     # note this was scraped before hand; the aim is to take ADDRESS here \n",
    "    merged_df = dataframe.merge(oarsystem_df[['sbl','ADDRESS']].drop_duplicates(subset = ['sbl']), on = ['sbl'])\n",
    "    missing_location_addresses = merged_df[merged_df['Location'].isna()]['ADDRESS']\n",
    "    df_to_geoencode = missing_location_addresses.str.split(',', expand=True)\n",
    "    df_to_geoencode.insert(2,'3','NY')\n",
    "    if os.path.exists('batch_file.csv'):\n",
    "        print(\"batch files have been added!\")\n",
    "    else:\n",
    "        df_to_geoencode.to_csv('batch_file.csv')\n",
    "    if os.path.exists('geocoderesult.csv'):\n",
    "        print(\"Locations have been geocoded!\")\n",
    "    else:\n",
    "        !curl --form addressFile=@batch_file.csv --form benchmark=9 https://geocoding.geo.census.gov/geocoder/locations/addressbatch --output geocoderesult.csv\n",
    "    result = pd.read_csv('geocoderesult.csv')\n",
    "    result = result.reset_index()[['level_0','Unnamed: 0']].set_index('level_0')\n",
    "    result['Unnamed: 0'] = result['Unnamed: 0'].apply(lambda x: '(' + x + ')' if x== x else np.nan)\n",
    "    indexes  = result.index\n",
    "    values = result.values.flatten().tolist()\n",
    "    dataframe.loc[indexes, 'Location'] = values\n",
    "    return dataframe\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dates(dataframe):\n",
    "    '''\n",
    "    for every anomoly, we try to replace them with the record given within the public records website \n",
    "    '''\n",
    "    dataframe = fixed_dataframe.copy()\n",
    "    index =dataframe[dataframe['date(search parcel)'].isna()].index\n",
    "    dataframe['Actual Date'] = dataframe['date(search parcel)']\n",
    "    dataframe.loc[index,'Actual Date'] = dataframe.loc[index,'date(public records)']\n",
    "    dates = pd.to_datetime(dataframe['date(search parcel)'],errors = 'coerce')\n",
    "    index_greater_2020 = dataframe[dates.apply(lambda x: True if x.year > 2020 else False)].index # index of anomolies\n",
    "    dataframe.loc[index_greater_2020,'Actual Date'] = dataframe.loc[index_greater_2020, 'date(public records)']\n",
    "    dataframe['Actual Date'] = pd.to_datetime(dataframe['Actual Date'], errors = 'coerce')\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_multiple_doc_types_column(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    group_by_doc_type = dataframe.groupby(['sbl','Actual Date'])['doc type'].count() \n",
    "    anomolies = group_by_doc_type[group_by_doc_type > 1].reset_index()[['sbl','Actual Date']]\n",
    "    anomolies['more than one doc type'] = True \n",
    "    dataframe = dataframe.merge(anomolies, on = ['sbl','Actual Date'],how = 'left',)\n",
    "    dataframe['more than one doc type'] = dataframe['more than one doc type'].fillna(False)\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier_data_pre_processing2(data_frame,open_dat):\n",
    "\n",
    "    # permits data acess \n",
    "    \n",
    "    permits_data =  pd.read_csv('https://data.buffalony.gov/api/views/9p2d-f3yt/rows.csv?accessType=DOWNLOAD', low_memory= False)\n",
    "    \n",
    "    permits_data['ISSUED'] = pd.to_datetime(permits_data['ISSUED'])\n",
    "    permits = open_dat[['SBL','PRINT KEY',]].merge(permits_data, on = 'SBL', how = 'right')\n",
    "    permits = permits.rename(columns = {'PRINT KEY':'sbl'}).drop('SBL',axis =1 )\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # -------  Weights and data initialization ------------------------\n",
    "    data_frame = data_frame.copy()\n",
    "    to_dataframe = defaultdict(list)\n",
    "    counter = 0\n",
    "    list_of_neighborhoods = data_frame['Neighborhood'].unique()[:-1]\n",
    "    w500, w300, w80, data_frame, unique_sbls = weights_initialization(data_frame, 'Location')\n",
    "    dates_six = pd.date_range(start=\"1993-12-01\",end=\"2021-12-01\", freq='A-DEC')[1:]\n",
    "    last_date = dates_six[0]\n",
    "    \n",
    "    # -------- loop feature collection --------------------------------\n",
    "    \n",
    "    for dates in dates_six[1:]: # we start from the second to the first date\n",
    "        timedelta_days = (dates - parser.parse('1854-10-01')).days\n",
    "        three_months = last_date + timedelta(90)\n",
    "        last_year = last_date - timedelta(365)\n",
    "        last_2year = last_date - timedelta(730)\n",
    "        last_3year = last_date - timedelta(1095)\n",
    "        last_45_year = last_date - timedelta(1825)\n",
    "        #------\n",
    "        length = data_frame[data_frame['Actual Date'] > last_date][data_frame['Actual Date'] <= dates]\n",
    "        sbls_bought_this_year =  np.array(length['sbl']) # drop duplicates dates here just to be safe \n",
    "        #----\n",
    "        length_3month = data_frame[data_frame['Actual Date'] > last_date][data_frame['Actual Date'] <= three_months]\n",
    "        sbls_bought_3month =  np.array(length_3month['sbl'])\n",
    "        #-----\n",
    "        length_last_year = data_frame[data_frame['Actual Date'] >= last_year][data_frame['Actual Date'] <= last_date]\n",
    "        sbls_bought_last_year =  set(np.array(length_last_year['sbl']))\n",
    "        perm_last_year = permits[permits['ISSUED'] >= last_year][permits['ISSUED'] <= last_date]\n",
    "        #----\n",
    "        length_last_2year = data_frame[data_frame['Actual Date'] >= last_2year][data_frame['Actual Date'] <= last_year]\n",
    "        sbls_bought_last_2year =  np.array(length_last_2year['sbl'])\n",
    "        perm_last_2year = permits[permits['ISSUED'] >= last_2year][permits['ISSUED'] <= last_year]\n",
    "        # -- \n",
    "        length_last_3year = data_frame[data_frame['Actual Date'] >= last_3year][data_frame['Actual Date'] <= last_2year]\n",
    "        sbls_bought_last_3year =  np.array(length_last_3year['sbl'])\n",
    "        perm_last_3year = permits[permits['ISSUED'] >= last_3year][permits['ISSUED'] <= last_2year]\n",
    "        # -- \n",
    "        length_last_45year = data_frame[data_frame['Actual Date'] >= last_45_year][data_frame['Actual Date'] <= last_3year]\n",
    "        sbls_bought_last_45year =  np.array(length_last_45year['sbl'])\n",
    "        perm_last_45year = permits[permits['ISSUED'] >= last_45_year][permits['ISSUED'] <= last_3year]\n",
    "        new_counter = 0\n",
    "        # must double check if this data path file is in the server \n",
    "        df = pd.read_csv('/data/gentrification/TAX_DATA/Tax_Data/tax_data-' + str(last_date.year) + '.csv')\n",
    "        try: \n",
    "            df_last3year = pd.read_csv('/data/gentrification/TAX_DATA/Tax_Data/tax_data-' + str(last_3year_bill_change) + '.csv')\n",
    "        except:\n",
    "            df_last3year = None \n",
    "        new_counter = 0\n",
    "        counter +=  1 \n",
    "        for sbl in unique_sbls:\n",
    "            to_dataframe['SBL'].append(sbl)# SBL COLUMN\n",
    "            to_dataframe['Timedelta'].append(timedelta_days)\n",
    "            to_dataframe['Year'].append(dates.year)\n",
    "            new_counter += 1 \n",
    "            print( \"OVERALL:\" + str(counter / len(dates_six[1:]) * 100) + \" |UNIQUE SBLS SECTION:\"+ str(new_counter / len(unique_sbls) * 100))\n",
    "            try:\n",
    "                bought_this_year = (data_frame[data_frame['sbl'] == sbl][data_frame['Actual Date'] > last_date].iloc[0]['Actual Date'] -last_date).days\n",
    "            except:\n",
    "                bought_this_year = 0\n",
    "            # bought_this_year = True if sbl in sbls_bought_this_year else False\n",
    "            to_dataframe['If Bought This Year'].append(bought_this_year) # IF HOUSE BOUGHT THIS YEAR COLUMN\n",
    "            bought_first_three = True if sbl in sbls_bought_3month else False\n",
    "            to_dataframe['Bought The First Three Months This Year'].append(bought_first_three) # IF HOUSE IS BOUGHT THE FIRST MONTHS THIS YEAR, THIS COLUMN WILL BE REMOVED\n",
    "            bought_last_year = True if sbl in sbls_bought_last_year else False\n",
    "            to_dataframe['If House is Bought Last Year'].append(bought_last_year) # IF HOUSE IS BOUGHT LAST YEAR\n",
    "            bought_last_2year = True if sbl in sbls_bought_last_2year else False\n",
    "            to_dataframe['If House is Bought Last 2 Years Ago'].append(bought_last_2year) # IF HOUSE IS BOUGHT LAST 2 Years Ago\n",
    "\n",
    "            #--------------------------------------------------------------------------------\n",
    "            neighbors_300 = w300.neighbors[sbl]\n",
    "            neighbors_500 = w500.neighbors[sbl]    # LIST OF NEIGHBORS \n",
    "            neighbors_80 = w80.neighbors[sbl]\n",
    "            n500 = data_frame[data_frame['sbl'].isin(neighbors_500)][data_frame['Actual Date'] <= last_date]\n",
    "            n300 = data_frame[data_frame['sbl'].isin(neighbors_300)][data_frame['Actual Date'] <= last_date]\n",
    "            n80 = data_frame[data_frame['sbl'].isin(neighbors_80)][data_frame['Actual Date'] <= last_date]\n",
    "\n",
    "\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "            # Column for number of houses (80m) bought last year ago\n",
    "            num_neighbors_bought_80_last_year = pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought Last Year'].append(num_neighbors_bought_80_last_year) \n",
    "            # Column for number of houses (80m) bought last 2 years ago\n",
    "            num80_2yearsago = pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 2 Years Ago'].append(num80_2yearsago)\n",
    "            # Column for number of houses (80m) bought last 3 years ago \n",
    "            num80_3yearsago = pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 3 Years Ago'].append(num80_3yearsago)\n",
    "            # Column for number of houses (80m) bought last 4 years ago \n",
    "            num80_45yearsago =pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 4 Years Ago'].append(num80_45yearsago)\n",
    "\n",
    "\n",
    "            #------------------------------------------------------------------------- # do duplicates here \n",
    "            # Column for number of houses bought (300m) bought last year ago \n",
    "            num_neighbors_bought_300_last_year = pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_300]).sum()  \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought Last Year'].append(num_neighbors_bought_300_last_year)\n",
    "            # Column for number of houses bought (300m) * Not Going to add this column\n",
    "            #num_neighbors_bought_300_3mnth =   pd.Series([ 1 for i in sbls_bought_3month if i in neighbors_300]).sum()     \n",
    "            # Column for number of houses bought (300m) bought 2 years ago   \n",
    "            num300_2yearsago =  pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_300]).sum() \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 2 years ago'].append(num300_2yearsago)\n",
    "            # Column for number of houses bought (300m) bought 3 years ago\n",
    "            num300_3yearsago =  pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_300]).sum()   \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 3 years ago'].append(num300_3yearsago)\n",
    "            # Column for number of houses bought (300m) bought 3 years ago \n",
    "            num300_45yearsago = pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_300]).sum()  \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 4-5 years ago'].append(num300_45yearsago)\n",
    "           # ------------------------------------------------------------------------------------------\n",
    "            #num_neighbors_bought_500_6mnth =  pd.Series([ 1 for i in sbls_bought_this_year if i in neighbors_500]).sum()  \n",
    "            #num_neighbors_bought_500_3mnth =  pd.Series([ 1 for i in sbls_bought_3month if i in neighbors_500]).sum()   \n",
    "            # Column for number of houses bought (500m) last year ago \n",
    "            num500_1yearsago =  pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_500]).sum() \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought last year ago'].append(num500_1yearsago)\n",
    "            # Column for number of houses bought (500m) last 2 years ago \n",
    "            num500_2yearsago =  pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_500]).sum() \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 2 years ago'].append(num500_2yearsago)\n",
    "            # Column for number of houses bought (500m) last 3 years ago \n",
    "            num500_3yearsago =  pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_500]).sum()  \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 3 years ago'].append(num500_3yearsago)\n",
    "            # Column for number of houses bought (500m) last 4-5 years ago \n",
    "            num500_45yearsago = pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_500]).sum()   \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 4-5 years ago'].append(num500_45yearsago)\n",
    "            #print(num_neighbors_bought_500_6mnth)   \n",
    "\n",
    "            to_dataframe['Year | Month'].append(str(dates.year) + \"|\" + str(dates.month))\n",
    "            #----------------PERMITS-----------------------------------------------------------------\n",
    "\n",
    "            perm_500_lst_year =  perm_last_year[perm_last_year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_2year500 = perm_last_2year[perm_last_2year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_3year500 = perm_last_3year[perm_last_3year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_45year500 = perm_last_45year[perm_last_45year['sbl'].isin(neighbors_500)]\n",
    "\n",
    "\n",
    "\n",
    "            #\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "            perm_80_lst_year =  perm_last_year[perm_last_year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_2year80 = perm_last_2year[perm_last_2year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_3year80 = perm_last_3year[perm_last_3year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_45year80 = perm_last_45year[perm_last_45year['sbl'].isin(neighbors_80)]\n",
    "\n",
    "            #-----------------------------------------------------------------------------------------\n",
    "\n",
    "            clear_output(wait=False)\n",
    "            ave_time_deltas = 0\n",
    "\n",
    "            ave_price_sold_last_year_500 = n500[n500['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_300 = n300[n300['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_80 = n80[n80['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_500_change = n500[n500['Actual Date'] >= last_3year][n500['Actual Date'] <= last_2year]['Price'].mean()\n",
    "            ave_price_sold_last_year_500_change = (ave_price_sold_last_year_500 - ave_price_sold_last_year_500_change) / ave_price_sold_last_year_500_change\n",
    "            ave_bill_neighbors500 = df[df['SBL'].isin(neighbors_500)]['Principal'].astype(float).mean()\n",
    "            sbl_last_year_500 = n500[n500['Actual Date'] >= last_year][['sbl','Price']].rename(columns = {'sbl':'SBL'}) # 500m radius bought last year \n",
    "            ratio = df[df['SBL'].isin(sbl_last_year_500['SBL'].unique())][['SBL','Principal']].set_index('SBL').to_dict()['Principal']\n",
    "            sbl_last_year_500['princ'] = sbl_last_year_500['SBL'].map(ratio)\n",
    "            num_foreclosures500 = len(n500[n500['Actual Date'] >= last_3year][n500['doc type'] == 'D1D']) \n",
    "            num_foreclosures300 = len(n300[n300['Actual Date'] >= last_3year][n300['doc type'] == 'D1D']) \n",
    "            num_foreclosures80 = len(n80[n80['Actual Date'] >= last_3year][n80['doc type'] == 'D1D']) \n",
    "            perms_3 = len(permits[permits['ISSUED'] >= last_3year][permits['ISSUED'] <= last_date][permits['sbl'].isin(neighbors_500)])\n",
    "            try:\n",
    "                rat = sbl_last_year_500[sbl_last_year_500['Price'] != 0][sbl_last_year_500['princ'] != 0] \n",
    "                mean_ratio = rat.apply(lambda x: x['Price'] / x['princ'], axis =1 ).apply(lambda i: i if isinstance(i,float) else np.nan).dropna().mean()\n",
    "\n",
    "                if not isinstance(mean_ratio,float):\n",
    "                    mean_ratio = 0\n",
    "            except Exception as e:\n",
    "                mean_ratio = 0 \n",
    "                print(e)\n",
    "\n",
    "            try:\n",
    "                my_bill = df[df['SBL'] == sbl]['Principal'].astype(float)\n",
    "                my_bill = my_bill.iloc[0] if len(my_bill) > 0 else 0  \n",
    "                std_bill = my_bill - ave_bill_neighbors500\n",
    "            except:\n",
    "                std_bill =  0\n",
    "            try:\n",
    "                my_bill_last3 = df_last3year[df_last3year['SBL'] == sbl]['Principal'].astype(float) if df_last3year != None else None \n",
    "                my_bill_last3 =  my_bill_last3.iloc[0] if my_bill_last3 != None and len(my_bill_last3) > 0 else 0  \n",
    "                bill_change= (my_bill - my_bill_last3) / my_bill_last3 if my_bill_last3 != -1 and my_bill != -1 else 0 \n",
    "            except: \n",
    "                bill_change = 0\n",
    "\n",
    "            ave_interest_near_me = df[df['SBL'].isin(neighbors_500)]['Pd Intr'].astype(float).mean()\n",
    "            try:\n",
    "                ave_time_deltas =  n500[n500['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas =  ave_time_deltas[ave_time_deltas  >= 0].mean() if len(ave_time_deltas) > 0else 0\n",
    "                ave_time_deltas300 =  n300[n300['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas300 =  ave_time_deltas300[ave_time_deltas300  >= 0].mean() if len(ave_time_deltas300) > 0 else 0 \n",
    "                ave_time_deltas80 =  n80[n80['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas80 =  ave_time_deltas80[ave_time_deltas80  >= 0].mean() if len(ave_time_deltas80) > 0 else 0\n",
    "\n",
    "                ave_p500 = permits[permits['sbl'].isin(neighbors_500)][permits['ISSUED'] <= last_date]['ISSUED'].apply(lambda p: (last_date - p).days).mean()\n",
    "                ave_p80 = permits[permits['sbl'].isin(neighbors_80)][permits['ISSUED'] <= last_date]['ISSUED'].apply(lambda p: (last_date - p).days).mean()\n",
    "            except Exception as e:\n",
    "                ave_time_deltas = 0\n",
    "                ave_time_deltas300 = 0\n",
    "                ave_time_deltas80 = 0\n",
    "                print(\"OH NO\")\n",
    "                print(e)\n",
    "                pass \n",
    "            try:\n",
    "                house_length_homeownership = (last_date - data_frame[data_frame['sbl'] == sbl][data_frame['Actual Date'] <= last_date].iloc[-1]['Actual Date']).days\n",
    "            except:\n",
    "                house_length_homeownership = 0\n",
    "            to_dataframe['Average length of homeownership (500m radius)'].append(ave_time_deltas)\n",
    "            to_dataframe['length of homeownership (this house)'].append(house_length_homeownership)\n",
    "            to_dataframe['Average bill of neighbors (500m radius) from last year'].append(ave_bill_neighbors500)\n",
    "            to_dataframe['This house\\'s bill last year'].append(my_bill)\n",
    "            to_dataframe['Average interest of neighbors (500m radius) last year'].append(ave_interest_near_me)\n",
    "            to_dataframe['Difference between SBL bill and neighbors (500m) last year'].append(std_bill)\n",
    "            to_dataframe['Average length of homeownership (300m radius)'].append(ave_time_deltas300)\n",
    "            to_dataframe['This sbl\\'s bill percent change from last 3 years ago to last year'].append(bill_change)\n",
    "            to_dataframe['Average length of homeownership (80m radius)'].append(ave_time_deltas80)\n",
    "            to_dataframe['Average price sold of neighbors (500m radius) last year'].append(ave_price_sold_last_year_500)\n",
    "            to_dataframe['Average price sold of neighbors (300m radius) last year'].append(ave_price_sold_last_year_300)\n",
    "            to_dataframe['Average price sold of neighbors (80m radius) last year'].append(ave_price_sold_last_year_80)\n",
    "            to_dataframe['Average percent change of house price transaction from last 3 years ago, to last year'].append(ave_price_sold_last_year_500_change)\n",
    "            to_dataframe['Mean ratio of bill to house price transaction from last year (500m raidus)'].append(mean_ratio)\n",
    "            to_dataframe['Number of permits last year in a (5oom) radius'].append(len(perm_500_lst_year))\n",
    "            to_dataframe['Number of permits last 2 years ago in a (500m) radius'].append(len(perm_last_2year500))\n",
    "            to_dataframe['Number of permits last 3 years ago in a (500m) radius'].append(len(perm_last_3year500))\n",
    "            to_dataframe['Number of permits last 4-5 years ago in a (500m) radius'].append(len(perm_last_45year500))\n",
    "            to_dataframe['Number of permits last year in a (80m) radius'].append(len(perm_80_lst_year))\n",
    "            to_dataframe['Number of permits last 2 years ago in a (80m) radius'].append(len(perm_last_2year80))\n",
    "            to_dataframe['Number of permits last 3 years ago in a (80m) radius'].append(len(perm_last_3year80))\n",
    "            to_dataframe['Number of permits last 4-5 years ago in a (80m) radius'].append(len(perm_last_45year80))\n",
    "            to_dataframe['Mean Value of work (Permits) in a (500m) radius last year'].append(perm_500_lst_year['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (500m) radius last 2 years ago'].append(perm_last_2year500['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (80m) radius last year'].append(perm_80_lst_year['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (80m) radius last 2 years ago'].append(perm_last_2year80['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Average length of time since the last permits issued in a (500m) radius'].append(ave_p500)\n",
    "            to_dataframe['Average length of time since the last permits issued in a (80m) radius'].append(ave_p80)\n",
    "            to_dataframe['Number of foreclosures in a (500m) radius, from last 3 years ago till last year'].append(num_foreclosures500)\n",
    "            to_dataframe['Number of foreclosures in a (300m) radius, from last 3 years ago till last year'].append(num_foreclosures300)\n",
    "            to_dataframe['Number of foreclosures in a (80m) radius, from last 3 years ago till last year'].append(num_foreclosures80)\n",
    "            to_dataframe['Number of Permits from last 3 years ago, to last year, in a (500m) radius'].append(perms_3)\n",
    "            try:\n",
    "                neighbor_name  = neigh[sbl]\n",
    "            except:\n",
    "                neighbor_name = 'UNKNOWN' \n",
    "\n",
    "            # one hot encode neighborhoods \n",
    "            for neighborhood in list_of_neighborhoods:\n",
    "                if neighborhood == neighborhood and neighborhood != neighbor_name:\n",
    "                    to_dataframe[neighborhood].append(0)\n",
    "                else: \n",
    "                    to_dataframe[neighbor_name].append(1) \n",
    "            # this way its just easier to name columns\n",
    "        last_date = dates\n",
    "    return pd.DataFrame(to_dataframe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_classifier_data_pre_processing3(data_frame,open_dat):\n",
    "    # i can do it before years\n",
    "    # permits data acess \n",
    "    \n",
    "    permits_data =  pd.read_csv('https://data.buffalony.gov/api/views/9p2d-f3yt/rows.csv?accessType=DOWNLOAD', low_memory= False)\n",
    "    \n",
    "    permits_data['ISSUED'] = pd.to_datetime(permits_data['ISSUED'])\n",
    "    permits = open_dat[['SBL','PRINT KEY',]].merge(permits_data, on = 'SBL', how = 'right')\n",
    "    permits = permits.rename(columns = {'PRINT KEY':'sbl'}).drop('SBL',axis =1 )\n",
    "    \n",
    "    # -----------------------------------------------------------------\n",
    "    # -------  Weights and data initialization ------------------------\n",
    "    data_frame = data_frame.copy()\n",
    "    to_dataframe = defaultdict(list)\n",
    "    counter = 0\n",
    "    list_of_neighborhoods = data_frame['Neighborhood'].unique()[:-1]\n",
    "    w500, w300, w80, data_frame, unique_sbls = weights_initialization(data_frame, 'Location')\n",
    "    dates_six = pd.date_range(start=\"1993-12-01\",end=\"2021-12-01\", freq='A-DEC')[1:]\n",
    "    last_date = dates_six[0]\n",
    "    \n",
    "    # -------- loop feature collection --------------------------------\n",
    "    \n",
    "    for dates in dates_six[1:]: # we start from the second to the first date\n",
    "        timedelta_days = (dates - parser.parse('1854-10-01')).days\n",
    "        three_months = last_date + timedelta(90)\n",
    "        last_year = last_date - timedelta(365)\n",
    "        last_2year = last_date - timedelta(730)\n",
    "        last_3year = last_date - timedelta(1095)\n",
    "        last_45_year = last_date - timedelta(1825)\n",
    "        #------\n",
    "        length = data_frame[data_frame['Actual Date'] > last_date][data_frame['Actual Date'] <= dates]\n",
    "        sbls_bought_this_year =  np.array(length['sbl']) # drop duplicates dates here just to be safe \n",
    "        #----\n",
    "        length_3month = data_frame[data_frame['Actual Date'] > last_date][data_frame['Actual Date'] <= three_months]\n",
    "        sbls_bought_3month =  np.array(length_3month['sbl'])\n",
    "        #-----\n",
    "        length_last_year = data_frame[data_frame['Actual Date'] >= last_year][data_frame['Actual Date'] <= last_date]\n",
    "        sbls_bought_last_year =  set(np.array(length_last_year['sbl']))\n",
    "        perm_last_year = permits[permits['ISSUED'] >= last_year][permits['ISSUED'] <= last_date]\n",
    "        #----\n",
    "        length_last_2year = data_frame[data_frame['Actual Date'] >= last_2year][data_frame['Actual Date'] <= last_year]\n",
    "        sbls_bought_last_2year =  np.array(length_last_2year['sbl'])\n",
    "        perm_last_2year = permits[permits['ISSUED'] >= last_2year][permits['ISSUED'] <= last_year]\n",
    "        # -- \n",
    "        length_last_3year = data_frame[data_frame['Actual Date'] >= last_3year][data_frame['Actual Date'] <= last_2year]\n",
    "        sbls_bought_last_3year =  np.array(length_last_3year['sbl'])\n",
    "        perm_last_3year = permits[permits['ISSUED'] >= last_3year][permits['ISSUED'] <= last_2year]\n",
    "        # -- \n",
    "        length_last_45year = data_frame[data_frame['Actual Date'] >= last_45_year][data_frame['Actual Date'] <= last_3year]\n",
    "        sbls_bought_last_45year =  np.array(length_last_45year['sbl'])\n",
    "        perm_last_45year = permits[permits['ISSUED'] >= last_45_year][permits['ISSUED'] <= last_3year]\n",
    "        new_counter = 0\n",
    "        # must double check if this data path file is in the server \n",
    "        df = pd.read_csv('/data/gentrification/TAX_DATA/Tax_Data/tax_data-' + str(last_date.year) + '.csv')\n",
    "        try: \n",
    "            df_last3year = pd.read_csv('/data/gentrification/TAX_DATA/Tax_Data/tax_data-' + str(last_3year_bill_change) + '.csv')\n",
    "        except:\n",
    "            df_last3year = None \n",
    "        new_counter = 0\n",
    "        counter +=  1 \n",
    "        for sbl in unique_sbls:\n",
    "            to_dataframe['SBL'].append(sbl)# SBL COLUMN\n",
    "            to_dataframe['Timedelta'].append(timedelta_days)\n",
    "            to_dataframe['Year'].append(dates.year)\n",
    "            new_counter += 1 \n",
    "            print( \"OVERALL:\" + str(counter / len(dates_six[1:]) * 100) + \" |UNIQUE SBLS SECTION:\"+ str(new_counter / len(unique_sbls) * 100))\n",
    "            try:\n",
    "                bought_this_year = (data_frame[data_frame['sbl'] == sbl][data_frame['Actual Date'] > last_date].iloc[0]['Actual Date'] -last_date).days\n",
    "            except:\n",
    "                bought_this_year = 0\n",
    "            # bought_this_year = True if sbl in sbls_bought_this_year else False\n",
    "            to_dataframe['If Bought This Year'].append(bought_this_year) # IF HOUSE BOUGHT THIS YEAR COLUMN\n",
    "            bought_first_three = True if sbl in sbls_bought_3month else False\n",
    "            to_dataframe['Bought The First Three Months This Year'].append(bought_first_three) # IF HOUSE IS BOUGHT THE FIRST MONTHS THIS YEAR, THIS COLUMN WILL BE REMOVED\n",
    "            bought_last_year = True if sbl in sbls_bought_last_year else False\n",
    "            to_dataframe['If House is Bought Last Year'].append(bought_last_year) # IF HOUSE IS BOUGHT LAST YEAR\n",
    "            bought_last_2year = True if sbl in sbls_bought_last_2year else False\n",
    "            to_dataframe['If House is Bought Last 2 Years Ago'].append(bought_last_2year) # IF HOUSE IS BOUGHT LAST 2 Years Ago\n",
    "\n",
    "            #--------------------------------------------------------------------------------\n",
    "            neighbors_300 = w300.neighbors[sbl]\n",
    "            neighbors_500 = w500.neighbors[sbl]    # LIST OF NEIGHBORS \n",
    "            neighbors_80 = w80.neighbors[sbl]\n",
    "            n500 = data_frame[data_frame['sbl'].isin(neighbors_500)][data_frame['Actual Date'] <= last_date]\n",
    "            n300 = data_frame[data_frame['sbl'].isin(neighbors_300)][data_frame['Actual Date'] <= last_date]\n",
    "            n80 = data_frame[data_frame['sbl'].isin(neighbors_80)][data_frame['Actual Date'] <= last_date]\n",
    "\n",
    "\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "            # Column for number of houses (80m) bought last year ago\n",
    "            num_neighbors_bought_80_last_year = pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought Last Year'].append(num_neighbors_bought_80_last_year) \n",
    "            # Column for number of houses (80m) bought last 2 years ago\n",
    "            num80_2yearsago = pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 2 Years Ago'].append(num80_2yearsago)\n",
    "            # Column for number of houses (80m) bought last 3 years ago \n",
    "            num80_3yearsago = pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 3 Years Ago'].append(num80_3yearsago)\n",
    "            # Column for number of houses (80m) bought last 4 years ago \n",
    "            num80_45yearsago =pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_80]).sum()\n",
    "            to_dataframe['Number of Houses (80m radius) Houses Bought 4 Years Ago'].append(num80_45yearsago)\n",
    "\n",
    "\n",
    "            #------------------------------------------------------------------------- # do duplicates here \n",
    "            # Column for number of houses bought (300m) bought last year ago \n",
    "            num_neighbors_bought_300_last_year = pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_300]).sum()  \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought Last Year'].append(num_neighbors_bought_300_last_year)\n",
    "            # Column for number of houses bought (300m) * Not Going to add this column\n",
    "            #num_neighbors_bought_300_3mnth =   pd.Series([ 1 for i in sbls_bought_3month if i in neighbors_300]).sum()     \n",
    "            # Column for number of houses bought (300m) bought 2 years ago   \n",
    "            num300_2yearsago =  pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_300]).sum() \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 2 years ago'].append(num300_2yearsago)\n",
    "            # Column for number of houses bought (300m) bought 3 years ago\n",
    "            num300_3yearsago =  pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_300]).sum()   \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 3 years ago'].append(num300_3yearsago)\n",
    "            # Column for number of houses bought (300m) bought 3 years ago \n",
    "            num300_45yearsago = pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_300]).sum()  \n",
    "            to_dataframe['Number of Houses (300m radius) Houses Bought 4-5 years ago'].append(num300_45yearsago)\n",
    "           # ------------------------------------------------------------------------------------------\n",
    "            #num_neighbors_bought_500_6mnth =  pd.Series([ 1 for i in sbls_bought_this_year if i in neighbors_500]).sum()  \n",
    "            #num_neighbors_bought_500_3mnth =  pd.Series([ 1 for i in sbls_bought_3month if i in neighbors_500]).sum()   \n",
    "            # Column for number of houses bought (500m) last year ago \n",
    "            num500_1yearsago =  pd.Series([ 1 for i in sbls_bought_last_year if i in neighbors_500]).sum() \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought last year ago'].append(num500_1yearsago)\n",
    "            # Column for number of houses bought (500m) last 2 years ago \n",
    "            num500_2yearsago =  pd.Series([ 1 for i in sbls_bought_last_2year if i in neighbors_500]).sum() \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 2 years ago'].append(num500_2yearsago)\n",
    "            # Column for number of houses bought (500m) last 3 years ago \n",
    "            num500_3yearsago =  pd.Series([ 1 for i in sbls_bought_last_3year if i in neighbors_500]).sum()  \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 3 years ago'].append(num500_3yearsago)\n",
    "            # Column for number of houses bought (500m) last 4-5 years ago \n",
    "            num500_45yearsago = pd.Series([ 1 for i in sbls_bought_last_45year if i in neighbors_500]).sum()   \n",
    "            to_dataframe['Number of Houses (500m radius) Houses Bought 4-5 years ago'].append(num500_45yearsago)\n",
    "            #print(num_neighbors_bought_500_6mnth)   \n",
    "\n",
    "            to_dataframe['Year | Month'].append(str(dates.year) + \"|\" + str(dates.month))\n",
    "            #----------------PERMITS-----------------------------------------------------------------\n",
    "\n",
    "            perm_500_lst_year =  perm_last_year[perm_last_year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_2year500 = perm_last_2year[perm_last_2year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_3year500 = perm_last_3year[perm_last_3year['sbl'].isin(neighbors_500)]\n",
    "            perm_last_45year500 = perm_last_45year[perm_last_45year['sbl'].isin(neighbors_500)]\n",
    "\n",
    "\n",
    "\n",
    "            #\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n",
    "            perm_80_lst_year =  perm_last_year[perm_last_year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_2year80 = perm_last_2year[perm_last_2year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_3year80 = perm_last_3year[perm_last_3year['sbl'].isin(neighbors_80)]\n",
    "            perm_last_45year80 = perm_last_45year[perm_last_45year['sbl'].isin(neighbors_80)]\n",
    "\n",
    "            #-----------------------------------------------------------------------------------------\n",
    "\n",
    "            clear_output(wait=False)\n",
    "            ave_time_deltas = 0\n",
    "\n",
    "            ave_price_sold_last_year_500 = n500[n500['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_300 = n300[n300['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_80 = n80[n80['Actual Date'] >= last_year]['Price'].dropna().mean()\n",
    "            ave_price_sold_last_year_500_change = n500[n500['Actual Date'] >= last_3year][n500['Actual Date'] <= last_2year]['Price'].mean()\n",
    "            ave_price_sold_last_year_500_change = (ave_price_sold_last_year_500 - ave_price_sold_last_year_500_change) / ave_price_sold_last_year_500_change\n",
    "            ave_bill_neighbors500 = df[df['SBL'].isin(neighbors_500)]['Principal'].astype(float).mean()\n",
    "            sbl_last_year_500 = n500[n500['Actual Date'] >= last_year][['sbl','Price']].rename(columns = {'sbl':'SBL'}) # 500m radius bought last year \n",
    "            ratio = df[df['SBL'].isin(sbl_last_year_500['SBL'].unique())][['SBL','Principal']].set_index('SBL').to_dict()['Principal']\n",
    "            sbl_last_year_500['princ'] = sbl_last_year_500['SBL'].map(ratio)\n",
    "            num_foreclosures500 = len(n500[n500['Actual Date'] >= last_3year][n500['doc type'] == 'D1D']) \n",
    "            num_foreclosures300 = len(n300[n300['Actual Date'] >= last_3year][n300['doc type'] == 'D1D']) \n",
    "            num_foreclosures80 = len(n80[n80['Actual Date'] >= last_3year][n80['doc type'] == 'D1D']) \n",
    "            perms_3 = len(permits[permits['ISSUED'] >= last_3year][permits['ISSUED'] <= last_date][permits['sbl'].isin(neighbors_500)])\n",
    "            try:\n",
    "                rat = sbl_last_year_500[sbl_last_year_500['Price'] != 0][sbl_last_year_500['princ'] != 0] \n",
    "                mean_ratio = rat.apply(lambda x: x['Price'] / x['princ'], axis =1 ).apply(lambda i: i if isinstance(i,float) else np.nan).dropna().mean()\n",
    "\n",
    "                if not isinstance(mean_ratio,float):\n",
    "                    mean_ratio = 0\n",
    "            except Exception as e:\n",
    "                mean_ratio = 0 \n",
    "                print(e)\n",
    "\n",
    "            try:\n",
    "                my_bill = df[df['SBL'] == sbl]['Principal'].astype(float)\n",
    "                my_bill = my_bill.iloc[0] if len(my_bill) > 0 else 0  \n",
    "                std_bill = my_bill - ave_bill_neighbors500\n",
    "            except:\n",
    "                std_bill =  0\n",
    "            try:\n",
    "                my_bill_last3 = df_last3year[df_last3year['SBL'] == sbl]['Principal'].astype(float) if df_last3year != None else None \n",
    "                my_bill_last3 =  my_bill_last3.iloc[0] if my_bill_last3 != None and len(my_bill_last3) > 0 else 0  \n",
    "                bill_change= (my_bill - my_bill_last3) / my_bill_last3 if my_bill_last3 != -1 and my_bill != -1 else 0 \n",
    "            except: \n",
    "                bill_change = 0\n",
    "\n",
    "            ave_interest_near_me = df[df['SBL'].isin(neighbors_500)]['Pd Intr'].astype(float).mean()\n",
    "            try:\n",
    "                ave_time_deltas =  n500[n500['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas =  ave_time_deltas[ave_time_deltas  >= 0].mean() if len(ave_time_deltas) > 0else 0\n",
    "                ave_time_deltas300 =  n300[n300['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas300 =  ave_time_deltas300[ave_time_deltas300  >= 0].mean() if len(ave_time_deltas300) > 0 else 0 \n",
    "                ave_time_deltas80 =  n80[n80['Actual Date'] <= last_date].groupby('sbl').apply(lambda grp: (last_date - grp['Actual Date'].iloc[-1]).days)\n",
    "                ave_time_deltas80 =  ave_time_deltas80[ave_time_deltas80  >= 0].mean() if len(ave_time_deltas80) > 0 else 0\n",
    "\n",
    "                ave_p500 = permits[permits['sbl'].isin(neighbors_500)][permits['ISSUED'] <= last_date]['ISSUED'].apply(lambda p: (last_date - p).days).mean()\n",
    "                ave_p80 = permits[permits['sbl'].isin(neighbors_80)][permits['ISSUED'] <= last_date]['ISSUED'].apply(lambda p: (last_date - p).days).mean()\n",
    "            except Exception as e:\n",
    "                ave_time_deltas = 0\n",
    "                ave_time_deltas300 = 0\n",
    "                ave_time_deltas80 = 0\n",
    "                print(\"OH NO\")\n",
    "                print(e)\n",
    "                pass \n",
    "            try:\n",
    "                house_length_homeownership = (last_date - data_frame[data_frame['sbl'] == sbl][data_frame['Actual Date'] <= last_date].iloc[-1]['Actual Date']).days\n",
    "            except:\n",
    "                house_length_homeownership = 0\n",
    "            to_dataframe['Average length of homeownership (500m radius)'].append(ave_time_deltas)\n",
    "            to_dataframe['length of homeownership (this house)'].append(house_length_homeownership)\n",
    "            to_dataframe['Average bill of neighbors (500m radius) from last year'].append(ave_bill_neighbors500)\n",
    "            to_dataframe['This house\\'s bill last year'].append(my_bill)\n",
    "            to_dataframe['Average interest of neighbors (500m radius) last year'].append(ave_interest_near_me)\n",
    "            to_dataframe['Difference between SBL bill and neighbors (500m) last year'].append(std_bill)\n",
    "            to_dataframe['Average length of homeownership (300m radius)'].append(ave_time_deltas300)\n",
    "            to_dataframe['This sbl\\'s bill percent change from last 3 years ago to last year'].append(bill_change)\n",
    "            to_dataframe['Average length of homeownership (80m radius)'].append(ave_time_deltas80)\n",
    "            to_dataframe['Average price sold of neighbors (500m radius) last year'].append(ave_price_sold_last_year_500)\n",
    "            to_dataframe['Average price sold of neighbors (300m radius) last year'].append(ave_price_sold_last_year_300)\n",
    "            to_dataframe['Average price sold of neighbors (80m radius) last year'].append(ave_price_sold_last_year_80)\n",
    "            to_dataframe['Average percent change of house price transaction from last 3 years ago, to last year'].append(ave_price_sold_last_year_500_change)\n",
    "            to_dataframe['Mean ratio of bill to house price transaction from last year (500m raidus)'].append(mean_ratio)\n",
    "            to_dataframe['Number of permits last year in a (5oom) radius'].append(len(perm_500_lst_year))\n",
    "            to_dataframe['Number of permits last 2 years ago in a (500m) radius'].append(len(perm_last_2year500))\n",
    "            to_dataframe['Number of permits last 3 years ago in a (500m) radius'].append(len(perm_last_3year500))\n",
    "            to_dataframe['Number of permits last 4-5 years ago in a (500m) radius'].append(len(perm_last_45year500))\n",
    "            to_dataframe['Number of permits last year in a (80m) radius'].append(len(perm_80_lst_year))\n",
    "            to_dataframe['Number of permits last 2 years ago in a (80m) radius'].append(len(perm_last_2year80))\n",
    "            to_dataframe['Number of permits last 3 years ago in a (80m) radius'].append(len(perm_last_3year80))\n",
    "            to_dataframe['Number of permits last 4-5 years ago in a (80m) radius'].append(len(perm_last_45year80))\n",
    "            to_dataframe['Mean Value of work (Permits) in a (500m) radius last year'].append(perm_500_lst_year['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (500m) radius last 2 years ago'].append(perm_last_2year500['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (80m) radius last year'].append(perm_80_lst_year['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Mean Value of work (Permits) in a (80m) radius last 2 years ago'].append(perm_last_2year80['VALUE OF WORK'].mean())\n",
    "            to_dataframe['Average length of time since the last permits issued in a (500m) radius'].append(ave_p500)\n",
    "            to_dataframe['Average length of time since the last permits issued in a (80m) radius'].append(ave_p80)\n",
    "            to_dataframe['Number of foreclosures in a (500m) radius, from last 3 years ago till last year'].append(num_foreclosures500)\n",
    "            to_dataframe['Number of foreclosures in a (300m) radius, from last 3 years ago till last year'].append(num_foreclosures300)\n",
    "            to_dataframe['Number of foreclosures in a (80m) radius, from last 3 years ago till last year'].append(num_foreclosures80)\n",
    "            to_dataframe['Number of Permits from last 3 years ago, to last year, in a (500m) radius'].append(perms_3)\n",
    "            try:\n",
    "                neighbor_name  = neigh[sbl]\n",
    "            except:\n",
    "                neighbor_name = 'UNKNOWN' \n",
    "\n",
    "            # one hot encode neighborhoods \n",
    "            for neighborhood in list_of_neighborhoods:\n",
    "                if neighborhood == neighborhood and neighborhood != neighbor_name:\n",
    "                    to_dataframe[neighborhood].append(0)\n",
    "                else: \n",
    "                    to_dataframe[neighbor_name].append(1) \n",
    "            # this way its just easier to name columns\n",
    "        last_date = dates\n",
    "    return pd.DataFrame(to_dataframe)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
