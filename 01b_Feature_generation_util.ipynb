{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neutral-round",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janvolta/.conda/envs/volt_env/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n",
      "/home/janvolta/.conda/envs/volt_env/lib/python3.7/site-packages/numba/np/ufunc/parallel.py:355: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 10005. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import utm\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import pysal as ps\n",
    "from IPython.display import clear_output\n",
    "from multiprocessing.pool import Pool\n",
    "import concurrent\n",
    "from splot.esda import lisa_cluster\n",
    "import sklearn\n",
    "import esda\n",
    "x_range = None \n",
    "y_range = None \n",
    "mat_contig = None \n",
    "total_matrix = None \n",
    "matrix_transaction = None \n",
    "matrix_percentages = None \n",
    "matrix_median_prices = None \n",
    "matrix_cells = None \n",
    "cell = None \n",
    "w = None \n",
    "#parks_df = gpd.read_file('https://data.buffalony.gov/api/geospatial/ew8t-dhy7?method=export&format=Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instructional-cache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geopandas_formulation(df):\n",
    "    global parks_df\n",
    "    locations_sbls = new_df['Location'].apply(lambda x: [ float(n.replace('(','').replace(')',''))  for n in x.split(',')] if x == x else np.nan)\n",
    "    gdf = gpd.GeoDataFrame(new_df, geometry=gpd.points_from_xy(locations_sbls.apply(lambda x: x[1]), locations_sbls.apply(lambda y: y[0])))\n",
    "    #gdf = gpd.GeoDataFrame(new_df, geometry=gpd.points_from_xy(new_df['locs'].apply(lambda x: x[0]), new_df['locs'].apply(lambda y: y[1])))\n",
    "    gdf.crs = {'init' :'epsg:4326'}\n",
    "    gdf = gdf.to_crs(epsg=3857)\n",
    "    #gdf = gdf.to_crs(parks_df.crs)\n",
    "    gdf['Actual Date'] = pd.to_datetime(gdf['Actual Date'])\n",
    "    gdf['year'] = gdf['Actual Date'].apply(lambda x: x.year)\n",
    "    gdf['month'] = gdf['Actual Date'].apply(lambda x: x.month)\n",
    "    gdf['consideration'] = gdf['consideration'].str.replace('$','').str.replace(',','').astype(float)\n",
    "    gdf = gdf[gdf['consideration'] > 5]\n",
    "    years_list = {}\n",
    "    months_list = {}\n",
    "    for name,grp in gdf.groupby('year'):\n",
    "        years_list[name] = grp.drop_duplicates(subset=['sbl']) \n",
    "    for name, grp in gdf.groupby(['year','month']):\n",
    "        months_list[name] = grp.drop_duplicates(subset = ['sbl'])\n",
    "    return gdf, years_list, months_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cordless-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_formation(gdf_unique_houses, n_cells):\n",
    "    global x_range \n",
    "    global y_range \n",
    "    global matrix_cells \n",
    "    global cell \n",
    "    xmin, ymin, xmax, ymax= gdf_unique_houses.total_bounds\n",
    "    # how many cells across and down\n",
    "    n_cells=n_cells\n",
    "    cell_size = (xmax-xmin)/n_cells\n",
    "    # projection of the grid\n",
    "    crs = \"+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs\"\n",
    "    # create the cells in a loop\n",
    "    x_range = np.arange(xmin, xmax+cell_size, cell_size )\n",
    "    y_range = np.arange(ymin, ymax+cell_size, cell_size)\n",
    "    indexes = []\n",
    "    matrix_cells = Matrix = [[0 for x in range(len(x_range))] for y in range(len(y_range))] \n",
    "    matrix_binomial = [[[] for x in range(len(x_range))] for y in range(len(y_range))] \n",
    "    # it goes.. up down \n",
    "    grid_cells = []\n",
    "    #reversed(list(range(len(np.arange(ymin, ymax+cell_size, cell_size)))))\n",
    "    for xidx,x0 in enumerate(np.arange(xmin, xmax+cell_size, cell_size )):\n",
    "        yidx = len(np.arange(ymin, ymax+cell_size, cell_size)) - 1\n",
    "        for y0 in np.arange(ymin, ymax+cell_size, cell_size):\n",
    "            # bounds\n",
    "            x1 = x0-cell_size\n",
    "            y1 = y0+cell_size\n",
    "            grid_cells.append( shapely.geometry.box(x0, y0, x1, y1)  )\n",
    "            matrix_cells[yidx][xidx] = shapely.geometry.box(x0, y0, x1, y1)\n",
    "            indexes.append( str(yidx) + ',' + str(xidx))\n",
    "            yidx -= 1\n",
    "    cell = gpd.GeoDataFrame(grid_cells, columns=['geometry'],index = indexes)\n",
    "    cell.set_crs(\"EPSG:3857\")\n",
    "    return cell, grid_cells, matrix_cells, indexes, cell_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hazardous-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_formation(cell,indexes, kmax):\n",
    "    global mat_contig\n",
    "    global w \n",
    "    w = ps.lib.weights.contiguity.Queen.from_dataframe(cell,ids = indexes,)\n",
    "    w5 = ps.lib.weights.order(w, kmax=5)\n",
    "    mat_contig = pd.DataFrame(w5,index = w5.keys())\n",
    "    return mat_contig, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "forbidden-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_matrix_allocation(matrix_cells,gdf_unique_houses):\n",
    "    global total_matrix\n",
    "    global x_range\n",
    "    global y_range \n",
    "    timer = 0\n",
    "    \n",
    "    total_matrix = [[[] for x in range(len(x_range))] for y in range(len(y_range))] \n",
    "    \n",
    "    for x in range(len(x_range)):\n",
    "        for y in range(len(y_range)):\n",
    "            polygon = matrix_cells[y][x]\n",
    "            number_of_transactions = gdf_unique_houses.within(polygon).sum()\n",
    "            print(\"Running total matrix allocation\" )\n",
    "            total_matrix[y][x]  = number_of_transactions \n",
    "            timer += 1 \n",
    "            print(timer / (len(x_range) * len(y_range))) \n",
    "            clear_output(wait = True)\n",
    "    return total_matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "urban-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "lists_transactions = os.listdir('../../../data/gentrification/updated_folder')\n",
    "def to_csvs_cells(matrix_cells,gdf, n_cells):\n",
    "    timer = 0\n",
    "    global lists_transactions \n",
    "    to_add_string = str(n_cells) + 'x' + str(n_cells)\n",
    "    if to_add_string not in lists_transactions:\n",
    "        os.mkdir('celltransactions/' + to_add_string)\n",
    "    global x_range \n",
    "    global y_range \n",
    "    for x in range(len(x_range)):\n",
    "        for y in range(len(y_range)):\n",
    "            polygon = matrix_cells[y][x]\n",
    "            slice_poly = gdf[gdf.within(polygon)]\n",
    "            if len(slice_poly) == 0:\n",
    "                continue \n",
    "            cell_name = str(y) + ',' + str(x)\n",
    "            timer += 1 \n",
    "            print(n_cells)\n",
    "            print(timer / (len(x_range) * len(y_range)))\n",
    "            clear_output()\n",
    "            slice_poly.to_csv('updated_folder/' + to_add_string + '/'+ cell_name + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "communist-democracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1905"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "grand-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janvolta/.conda/envs/volt_env/lib/python3.7/site-packages/pyproj/crs/crs.py:53: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "/home/janvolta/.conda/envs/volt_env/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv('../../../data/gentrification/filtered_data.csv')\n",
    "df.head(5)\n",
    "# data filteration \n",
    "df = df[df['doc type'].isin(['D1A','DEED','D1B','D1BU'])]\n",
    "# remove nan \n",
    "series = df['Location'].apply(lambda x : x.split(',')[0][1:] if x == x  else np.nan).apply(lambda x: '-' in x if x == x else np.nan)\n",
    "index_of_faulty_locations = df[series == True].index\n",
    "new_vals = df.loc[index_of_faulty_locations]['Location'].apply(lambda x : '(' + x.split(',')[1][:-1] + ',' + x.split(',')[0][1:] + ')')\n",
    "df.at[index_of_faulty_locations,'Location'] = new_vals\n",
    "new_df = df[~df['Location'].isna()].copy() # remove NaN locations \n",
    "gdf,years_list, months_list = geopandas_formulation(new_df)\n",
    "gdf_unique_houses = gdf.drop_duplicates('sbl')['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-china",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ongoing-instrument",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_transaction_allocation(time_list,total_matrix, months = False):\n",
    "    global matrix_transaction\n",
    "    global x_range \n",
    "    global y_range \n",
    "    list_years = []\n",
    "    matrix_transaction = [[[] for x in range(len(x_range))] for y in range(len(y_range))] \n",
    "    matrix_non_transactions = [[[] for x in range(len(x_range))] for y in range(len(y_range))] \n",
    "    list_to_iter = reversed(sorted(time_list, key = lambda element: (element[0], element[1]) )) if months else sorted(time_list,reverse = True)\n",
    "    for gdf_year in list_to_iter:\n",
    "        gdf_sample = time_list[gdf_year].drop_duplicates(subset = 'sbl')\n",
    "        timer = 0\n",
    "        year = gdf_year if months else tuple(gdf_sample['year'].unique())\n",
    "        list_years.append(year)\n",
    "        g_sample = gdf_sample['geometry']\n",
    "        for x in range(len(x_range)):\n",
    "            for y in range(len(y_range)):\n",
    "                polygon = matrix_cells[y][x]\n",
    "                number_of_transactions = g_sample.within(polygon).sum()\n",
    "                number_of_transactions_opposite = total_matrix[y][x] - number_of_transactions\n",
    "                matrix_transaction[y][x].append(number_of_transactions)\n",
    "                matrix_non_transactions[y][x].append(number_of_transactions_opposite)\n",
    "                clear_output(wait = True)\n",
    "                print(\"running matrix_transaction_allocation\")\n",
    "                print(str(year))\n",
    "                timer += 1 \n",
    "                print(timer / (len(x_range) * len(y_range)))\n",
    "    return matrix_transaction, matrix_non_transactions,list_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "signal-gossip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/janvolta/wrap_up_folder'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-collapse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swedish-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_percentages_allocation(matrix_transaction,total_matrix):\n",
    "    # percentages bought matrix \n",
    "    global matrix_percentages\n",
    "    global x_range \n",
    "    global y_range \n",
    "    timer = 0\n",
    "    matrix_percentages = [[[] for x in range(len(x_range))] for y in range(len(y_range))] \n",
    "    for x in range(len(x_range)):\n",
    "        for y in range(len(y_range)):\n",
    "            transactions_list = matrix_transaction[y][x]\n",
    "            for idx,z in enumerate(transactions_list):\n",
    "                try:\n",
    "                    val = z / total_matrix[y][x]\n",
    "                    if val == val:\n",
    "                        matrix_percentages[y][x].append(val)\n",
    "                    else:\n",
    "                        matrix_percentages[y][x].append(0) \n",
    "                except:\n",
    "                    matrix_percentages[y][x].append(0)\n",
    "                print(\"running matrix percentages allocation\")\n",
    "                clear_output(wait = True)\n",
    "                timer +=1 \n",
    "                print(timer / (len(x_range) * len(y_range)))\n",
    "    return matrix_percentages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "designing-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_median_prices_allocation(time_list, months = False):\n",
    "    global matrix_median_prices\n",
    "    global x_range \n",
    "    global y_range \n",
    "    global matrix_cells \n",
    "    list_years_in_z = []\n",
    "    list_to_iter = reversed(sorted(time_list, key = lambda element: (element[0], element[1]) )) if months else sorted(time_list,reverse = True)\n",
    "    matrix_median_prices = [[[] for x in range(len(x_range))] for y in range(len(y_range))] \n",
    "    for gdf_time in list_to_iter:\n",
    "        mean_consideration = time_list[gdf_time].groupby('sbl')['consideration'].mean().to_dict()\n",
    "        gdf_sample = time_list[gdf_time].drop_duplicates(subset = 'sbl')\n",
    "        gdf_sample['mean consideration'] = gdf_sample['sbl'].map(mean_consideration)\n",
    "        year = gdf_time if months else tuple(gdf_sample['year'].unique())\n",
    "        list_years_in_z.append(year)\n",
    "        g_sample = gdf_sample['geometry']\n",
    "        timer = 0\n",
    "        \n",
    "        for x in range(len(x_range)):\n",
    "            for y in range(len(y_range)):\n",
    "                polygon = matrix_cells[y][x]\n",
    "                median_houseprice = gdf_sample[g_sample.within(polygon)]['mean consideration'].median()\n",
    "                if median_houseprice == median_houseprice:\n",
    "                    matrix_median_prices[y][x].append(median_houseprice)\n",
    "                else:\n",
    "                    matrix_median_prices[y][x].append(-1)\n",
    "                print(\"running matrix median prices allocation\")\n",
    "                print(\"year:\" + str(year))\n",
    "                timer += 1 \n",
    "                print(timer / (len(x_range) * len(y_range)))\n",
    "                clear_output(wait = True)\n",
    "    return matrix_median_prices, list_years_in_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advance-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features formulation\n",
    "def highest_valued_priced_cell_distance(x,y,z, order_contiguity = 1, lag = False):\n",
    "    indexes = mat_contig[str(y) + ',' + str(x)][mat_contig[str(y) + ',' + str(x)] <= order_contiguity].index\n",
    "   \n",
    "    highest_median = -1 \n",
    "    location = None \n",
    "    if lag == True:\n",
    "        lag_list = []\n",
    "    for y_,x_ in indexes.str.split(','):\n",
    "        median_price = matrix_median_prices[int(y_)][int(x_)][z] # it outputs -1 if empty cell or empty house prices \n",
    "        if lag == True:\n",
    "            lag_list.append(median_price)\n",
    "        if median_price > highest_median:\n",
    "            highest_median  = median_price \n",
    "            location = str(y_) + \",\" + str(x_)\n",
    "    if highest_median == -1:\n",
    "        return -1\n",
    "    return mat_contig[str(y) + ',' + str(x)].loc[location] if lag == False else np.array(lag_list).mean()\n",
    "   \n",
    "def highest_transactions_cell_distance(x,y,z, order_contiguity = 1, lag = False):\n",
    "    indexes = mat_contig[str(y) + ',' + str(x)][mat_contig[str(y) + ',' + str(x)] <= order_contiguity].index\n",
    "    try:\n",
    "        highest_transaction = -1 \n",
    "        location = None \n",
    "        if lag:\n",
    "            lag_list = []\n",
    "        for y_,x_ in indexes.str.split(','):\n",
    "            transaction = matrix_transaction[int(y_)][int(x_)][z]\n",
    "            if lag:\n",
    "                lag_list.append(transaction)\n",
    "            if transaction > highest_transaction:\n",
    "                highest_transaction  = transaction \n",
    "                location = str(y_) + \",\" + str(x_)\n",
    "        if highest_transaction == 0 or highest_transaction == -1:\n",
    "            return -1 \n",
    "        return mat_contig[str(y) + ',' + str(x)].loc[location] if lag == False else np.array(lag_list).mean()\n",
    "    except:\n",
    "        return -1 \n",
    "\n",
    "def highest_percentage_cell_distance(x,y,z, order_contiguity = 1, lag = False):\n",
    "    indexes = mat_contig[str(y) + ',' + str(x)][mat_contig[str(y) + ',' + str(x)] <= order_contiguity].index\n",
    "\n",
    "    highest_percentage = -1 \n",
    "    location = None \n",
    "    if lag:\n",
    "        lag_list = []\n",
    "    for y_,x_ in indexes.str.split(','):\n",
    "        percentage = matrix_percentages[int(y_)][int(x_)][z]\n",
    "        if lag:\n",
    "            lag_list.append(percentage)\n",
    "        if percentage > highest_percentage:\n",
    "            highest_percentage  = percentage \n",
    "            location = str(y_) + \",\" + str(x_)\n",
    "    if highest_percentage == 0 or highest_percentage == -1:\n",
    "        return -1 \n",
    "    return mat_contig[str(y) + ',' + str(x)].loc[location] if lag == False else np.array(lag_list).mean() \n",
    "    \n",
    "def distance_from_nearest_park(x,y):\n",
    "    polygon = matrix_cells[y][x]\n",
    "    return parks_df['geometry'].apply(lambda g:  g.distance(polygon) ).min()\n",
    "def addition_spatial_dependencies(z, prices = False, transactions = False, percentages = False):\n",
    "    cell_copy = cell.copy()\n",
    "    variables_to_add = []\n",
    "    if percentages:\n",
    "        matrix_call = matrix_percentages\n",
    "    elif prices: \n",
    "        matrix_call = matrix_median_prices\n",
    "    else: # then its transactions \n",
    "        matrix_call = matrix_transaction\n",
    "    for y,x in cell_copy.index.str.split(','):\n",
    "        variables_to_add.append(matrix_call[int(y)][int(x)][z])\n",
    "    cell_copy['val'] = variables_to_add \n",
    "    li = esda.Moran_Local(cell_copy['val'],w)\n",
    "    cell_copy['lisa category'] = li.q\n",
    "    cell_copy['local moran expected value'] = li.EI_sim\n",
    "    cell_copy['local moran p-value'] = li.p_sim\n",
    "    return cell_copy\n",
    "def find_lisa_val(cell_copy,x,y,column):\n",
    "    return cell_copy.loc[str(y) + ',' + str(x)][column]\n",
    "def lisa_highest_positive_distance(x,y,lisa_cells, order_contiguity = 1):\n",
    "    # buggy code \n",
    "    indexes = mat_contig[str(y) + ',' + str(x)][mat_contig[str(y) + ',' + str(x)] <= order_contiguity].index\n",
    "    highest_moran_i = -9999999\n",
    "    location = None \n",
    "    for y_,x_ in indexes.str.split(','):\n",
    "        lisaval = find_lisa_val(lisa_cells,x_,y_,'local moran expected value')\n",
    "        if lisaval > highest_moran_i:\n",
    "            highest_moran_i = lisaval\n",
    "            location = str(y_) + ',' + str(x_)\n",
    "    if highest_moran_i < 0: # this is because we want clustering of high values of transactions and high prices\n",
    "        return -1 \n",
    "    return mat_contig[str(y) + ',' + str(x)].loc[location] # returns distance in terms of order of contiguity\n",
    "    \n",
    "def distance_temporallag_addition(x,y,z,dictionary , number_of_years): # adds (X year ago ) column name\n",
    "    columns_check_list= []\n",
    "    # 'distance from highest valued cell a year ago'\n",
    "    for i in range(1,number_of_years+1):\n",
    "        result_price = highest_valued_priced_cell_distance(x,y,z+i)\n",
    "        result_transactions = highest_transactions_cell_distance(x,y,z+i)\n",
    "        column_name_highest_value = 'distance from highest valued cell ' + str(i) + ' years ago'\n",
    "        column_name_highest_trans = 'distance from highest transaction cell ' + str(i) + ' years ago'\n",
    "        if  column_name_highest_value in dictionary: \n",
    "            dictionary[column_name_highest_value].append(result_price)\n",
    "        else:\n",
    "            dictionary[column_name_highest_value] = []\n",
    "            dictionary[column_name_highest_value].append(result_price)\n",
    "        if column_name_highest_trans in dictionary: \n",
    "            dictionary[column_name_highest_trans].append(result_transactions)\n",
    "        else:\n",
    "            dictionary[column_name_highest_trans] = []\n",
    "            dictionary[column_name_highest_trans].append(result_transactions)\n",
    "        if (column_name_highest_value in columns_check_list) or (column_name_highest_trans in columns_check_list): # raise error\n",
    "            raise ValueError(\"buggy code\")\n",
    "        else:\n",
    "            columns_check_list.append(column_name_highest_value)\n",
    "            columns_check_list.append(column_name_highest_trans)\n",
    "def spatial_lag_time_price_lag_addition(x,y,z,dictionary, number_of_years, order_contiguity):\n",
    "    columns_check_list = []\n",
    "    for i in range(1, number_of_years +1):\n",
    "        for num_order in range(1, order_contiguity +1,3):\n",
    "            column_name = 'spatial lag of house price cells ('+ str(num_order) + ' order) ' + str(i) + ' year(s) ago'\n",
    "            if column_name in dictionary:\n",
    "                dictionary[column_name].append(highest_valued_priced_cell_distance(x,y,z+i,order_contiguity = num_order, lag = True ))\n",
    "            else:\n",
    "                dictionary[column_name] = []\n",
    "                dictionary[column_name].append(highest_valued_priced_cell_distance(x,y,z+i,order_contiguity = num_order, lag = True ))\n",
    "            if column_name in columns_check_list: # raise \n",
    "                raise ValueError(\"buggy code\")\n",
    "            else:\n",
    "                columns_check_list.append(column_name)\n",
    "def spatial_lag_time_transaction_lag_addition(x,y,z,dictionary, number_of_years, order_contiguity):\n",
    "    columns_check_list = []\n",
    "    for i in range(1, number_of_years +1):\n",
    "        for num_order in range(1, order_contiguity +1,3):\n",
    "            column_name = 'spatial lag of number of transaction cells ('+ str(num_order) + ' order) ' + str(i) + ' year(s) ago'\n",
    "            if column_name in dictionary:\n",
    "                dictionary[column_name].append(highest_transactions_cell_distance(x,y,z+i,order_contiguity = num_order, lag = True ))\n",
    "            else:\n",
    "                dictionary[column_name] = []\n",
    "                dictionary[column_name].append(highest_transactions_cell_distance(x,y,z+i,order_contiguity = num_order, lag = True ))\n",
    "            if column_name in columns_check_list: # raise error\n",
    "                raise ValueError(\"buggy code\")\n",
    "            else:\n",
    "                columns_check_list.append(column_name)\n",
    "def spatial_lag_time_percentages_lag_addition(x,y,z,dictionary, number_of_years, order_contiguity):\n",
    "    columns_check_list = []\n",
    "    # highest_percentage_cell_distance\n",
    "    for i in range(1, number_of_years +1):\n",
    "        for num_order in range(1, order_contiguity +1,3):\n",
    "            column_name = 'spatial lag of percentage of homes sold cells ('+ str(num_order) + ' order) ' + str(i) + ' year(s) ago'\n",
    "            if column_name in dictionary:\n",
    "                dictionary[column_name].append(highest_percentage_cell_distance(x,y,z+i,order_contiguity = num_order, lag = True ))\n",
    "            else:\n",
    "                dictionary[column_name] = []\n",
    "                dictionary[column_name].append(highest_percentage_cell_distance(x,y,z+i,order_contiguity = num_order, lag = True ))\n",
    "            if column_name in columns_check_list: # raise error\n",
    "                raise ValueError(\"buggy code\")\n",
    "            else:\n",
    "                columns_check_list.append(column_name) # you only want it to be appended once during this function call\n",
    "def temporal_lag_lisa(x,y, dictionary, lisa_cells, column_category ):\n",
    "    columns_check_list = []\n",
    "    for idx,cell_matrix in enumerate(lisa_cells):\n",
    "         # lisa additions + temporal lag \n",
    "          \n",
    "        lc,col_name_lc = find_lisa_val(cell_matrix,x,y,'lisa category'), 'lisa category (' + column_category + ') ' + str(idx + 1) + ' year(s) ago'\n",
    "        le,col_name_le  = find_lisa_val(cell_matrix,x,y, 'local moran expected value'), 'lisa moran expected value (' + column_category + ') ' + str(idx + 1) + ' year(s) ago'\n",
    "        lp,col_name_lp = find_lisa_val(cell_matrix,x,y,'local moran p-value'), 'lisa p-value (' + column_category + ') ' + str(idx + 1) + ' year(s) ago'\n",
    "        \n",
    "        if col_name_lc in dictionary:\n",
    "            dictionary[col_name_lc].append(lc)\n",
    "        else: \n",
    "            dictionary[col_name_lc] = []\n",
    "            dictionary[col_name_lc].append(lc)\n",
    "        if col_name_le in dictionary:\n",
    "            dictionary[col_name_le].append(le)\n",
    "        else: \n",
    "            dictionary[col_name_le] = []\n",
    "            dictionary[col_name_le].append(le)\n",
    "        if col_name_lp in dictionary:\n",
    "            dictionary[col_name_lp].append(le)\n",
    "        else:\n",
    "            dictionary[col_name_lp] = []\n",
    "            dictionary[col_name_lp].append(lp)\n",
    "            \n",
    "        if (col_name_lc in columns_check_list) or (col_name_le in columns_check_list) or (col_name_lp in columns_check_list):\n",
    "            raise ValueError(\"buggy code\")\n",
    "        else:\n",
    "            columns_check_list.append(col_name_lc)\n",
    "            columns_check_list.append(col_name_le)\n",
    "            columns_check_list.append(col_name_lp)\n",
    "def constant_variable_time_lags(matrix,x,y,z, dictionary,number_of_years,column_category):\n",
    "    columns_check_list = []\n",
    "    for i in range(1, number_of_years +1):\n",
    "        string_column = column_category + ' ' + str(i) + ' year(s) ago'\n",
    "        if string_column in dictionary:\n",
    "            dictionary[string_column].append(matrix[y][x][z+i])\n",
    "        else:\n",
    "            dictionary[string_column] = []\n",
    "            dictionary[string_column].append(matrix[y][x][z+i])\n",
    "        if string_column in columns_check_list:\n",
    "            raise ValueError(\"buggy code\")\n",
    "        else:\n",
    "            columns_check_list.append(string_column)\n",
    "def lisa_distance_cluster_lags(lisa_cells,x,y,dictionary, order_contiguity, column_category):\n",
    "    columns_check_list = []\n",
    "    for idx,cell_matrix in enumerate(lisa_cells):\n",
    "        for num_order in range(1, order_contiguity +1):\n",
    "            distance = lisa_highest_positive_distance(x,y,cell_matrix,order_contiguity= num_order)\n",
    "            column_name = 'distance from highest positive value clustering (lisa) ' + column_category + ' ' + str(idx+ 1) +' year(s) ago with ' + str(num_order) + ' orders of contiguity'\n",
    "            if column_name in dictionary:\n",
    "                dictionary[column_name].append(distance)\n",
    "            else:\n",
    "                dictionary[column_name] = []\n",
    "                dictionary[column_name].append(distance)\n",
    "            if column_name in columns_check_list:\n",
    "                raise ValueError(\"buggy code\")\n",
    "            else:\n",
    "                columns_check_list.append(column_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "announced-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_features(z_yr,number_of_years_time_lag = 6, months = False):\n",
    "    global total_matrix\n",
    "    global matrix_transaction\n",
    "    global matrix_percentages\n",
    "    global matrix_median_prices \n",
    "    global x_range \n",
    "    global y_range \n",
    "    z,yr = z_yr[0],z_yr[1]\n",
    "    total_length = len(x_range) * len(y_range)\n",
    "    to_append_dct = {'target': [], 'year': [],'cell name': [],'distance from nearest park':[],'total number of houses':[]}\n",
    "    lisa_cells_prices = [ addition_spatial_dependencies(z+i, prices = True) for i in range(1,number_of_years_time_lag+1)]\n",
    "    lisa_cells_transactions =   [ addition_spatial_dependencies(z+i, transactions = True) for i in range(1,number_of_years_time_lag+1)]\n",
    "    lisa_cells_percentages = [addition_spatial_dependencies(z+i, percentages = True) for i in range(1,number_of_years_time_lag+1)]\n",
    "    counter = 0\n",
    "    for x in range(len(x_range)):\n",
    "        for y in range(len(y_range)):\n",
    "            transactions =  matrix_transaction[y][x][z] # goes through 2017 first \n",
    "            percentage = matrix_percentages[y][x][z]\n",
    "            # if no homes then skip \n",
    "            to_append_dct['target'].append(percentage)\n",
    "            to_append_dct['year'].append(yr)\n",
    "            distance_temporallag_addition(x,y,z,to_append_dct, number_of_years = number_of_years_time_lag)\n",
    "            to_append_dct['distance from nearest park'].append(distance_from_nearest_park(x,y))\n",
    "            spatial_lag_time_price_lag_addition(x,y,z,to_append_dct, number_of_years = number_of_years_time_lag, order_contiguity = 5)\n",
    "            spatial_lag_time_transaction_lag_addition(x,y,z,to_append_dct, number_of_years = number_of_years_time_lag, order_contiguity = 5)\n",
    "            spatial_lag_time_percentages_lag_addition(x,y,z,to_append_dct, number_of_years = number_of_years_time_lag, order_contiguity = 5)\n",
    "          \n",
    "            # \n",
    "            temporal_lag_lisa(x,y,to_append_dct, lisa_cells_prices, 'median home prices')\n",
    "            temporal_lag_lisa(x,y,to_append_dct, lisa_cells_transactions, '# transactions')\n",
    "            temporal_lag_lisa(x,y,to_append_dct, lisa_cells_percentages, 'percentage house sold')\n",
    "            \n",
    "            # temporal constant time lags\n",
    "         \n",
    "            constant_variable_time_lags(matrix_median_prices, x,y,z,to_append_dct, number_of_years_time_lag, 'median home prices')\n",
    "            constant_variable_time_lags(matrix_transaction, x,y,z,to_append_dct, number_of_years_time_lag, 'number of transactions')\n",
    "            constant_variable_time_lags(matrix_percentages, x,y,z,to_append_dct, number_of_years_time_lag, 'percentage of homes sold')\n",
    "            \n",
    "            # distance from clustering lisas \n",
    "         \n",
    "            lisa_distance_cluster_lags(lisa_cells_prices,x,y,to_append_dct, order_contiguity=5, column_category='median home prices' )\n",
    "            lisa_distance_cluster_lags(lisa_cells_transactions,x,y,to_append_dct, order_contiguity=5, column_category='# transactions' )\n",
    "            lisa_distance_cluster_lags(lisa_cells_percentages,x,y,to_append_dct, order_contiguity=5, column_category='percentage house sold')\n",
    "            to_append_dct['total number of houses'].append(total_matrix[y][x])\n",
    "            to_append_dct['cell name'].append(str(y) + ',' + str(x))\n",
    "            counter += 1 \n",
    "            print(yr)\n",
    "            print(counter / total_length )\n",
    "            clear_output(wait = True)\n",
    "    return pd.DataFrame(to_append_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "behind-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocessing_feature_engineering_years(time_list):\n",
    "    lists_pds = []\n",
    "   \n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = []\n",
    "        for z,yr in enumerate(range(2020,2003,-1)):\n",
    "            args = (z,yr)\n",
    "            f1 = executor.submit(calculate_features, args)\n",
    "            results.append(f1)\n",
    "\n",
    "        for f in concurrent.futures.as_completed(results):\n",
    "            lists_pds.append(f.result())\n",
    "    return pd.concat(lists_pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocessing_feature_engineering_months(months_list):\n",
    "    lists_pds = []\n",
    "    months_list = sorted(time_list,reverse = True)\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = []\n",
    "        \n",
    "        for z,month in enumerate(months_list):\n",
    "            args = (z,yr)\n",
    "            f1 = executor.submit(calculate_features, args)\n",
    "            results.append(f1)\n",
    "\n",
    "        for f in concurrent.futures.as_completed(results):\n",
    "            lists_pds.append(f.result())\n",
    "    return pd.concat(lists_pds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_prediction_task(data_frame_model,percent_greater_than = 10):\n",
    "    data_frame_model = data_frame_model[data_frame_model['total number of houses'] > 0]\n",
    "    data_frame_model['target'] = data_frame_model['target'] *  100\n",
    "    data_frame_model['new_target'] = data_frame_model['target'] > percent_greater_than\n",
    "    target = data_frame_model[data_frame_model['year'] == 2018]\n",
    "    train = data_frame_model[data_frame_model['year'] < 2018]\n",
    "    X_train,y_train = train.drop(['target','year','new_target', 'cell name'], axis =1), train['new_target']\n",
    "    X_test, y_test = target.drop(['target','year','new_target', 'cell name'], axis =1 ), target['new_target']\n",
    "    clf = sklearn.ensemble.RandomForestClassifier(n_estimators= 200, verbose = 2,n_jobs = -1)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(sklearn.metrics.classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_prediction_task_yearprior(to_model):\n",
    "    to_model = to_model[to_model['total number of houses'] > 0]\n",
    "    predict_ = []\n",
    "    truth_  = [] \n",
    "    target = to_model[to_model['year'] == 2018]\n",
    "    train = to_model[to_model['year'] == 2017]\n",
    "    merged = target.merge(train, on  = 'cell name')\n",
    "    y_before,y_after = merged['new_target_y'], merged['new_target_x']\n",
    "    print(sklearn.metrics.classification_report(y_after, y_before))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
